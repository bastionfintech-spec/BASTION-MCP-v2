"""
MCF Labs Institutional Report Generator
=========================================
Generates Goldman/Citadel-grade research reports using:
- MCF Ultra quantitative engine (structure, volume, volatility, momentum)
- Live market data (Coinglass, Helsinki, Whale Alert)
- BASTION AI 32B for narrative synthesis

Report format mirrors institutional analyst notes:
- Thesis with conviction rating
- Key Drivers (quantitative backing)
- Risks & Warnings
- Valuation Scenarios (Bear/Base/Bull)
- Tactical Trade Structures
- OI/Funding/Flow metrics
- Audit trail & data provenance
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path

from .models import Report, ReportType, Bias, Confidence, TradeScenario

logger = logging.getLogger(__name__)

# Report type constants
INSTITUTIONAL_REPORT = "institutional_research"

# Analyst desk assignments by symbol category
DESK_MAP = {
    "BTC": "Macro / Digital Gold",
    "ETH": "Macro / L1 Infra",
    "SOL": "Macro / L1",
    "BNB": "Macro / Exchange",
    "XRP": "Macro / Payments",
    "AVAX": "Macro / L1",
    "LINK": "DeFi / Oracles",
    "ARB": "DeFi / L2",
    "OP": "DeFi / L2",
    "DOGE": "Macro / Meme",
    "ADA": "Macro / L1",
}

RATING_LABELS = {
    "STRONG_BUY": "Overweight",
    "BUY": "Overweight",
    "HOLD": "Equal-Weight",
    "SELL": "Underweight",
    "STRONG_SELL": "Underweight",
}


class InstitutionalReportGenerator:
    """
    Generates institutional-grade research reports.

    Pipeline:
    1. Fetch live data (Coinglass + Helsinki + Whale Alert)
    2. Run MCF Ultra quant analysis
    3. Build structured quant package
    4. Send to BASTION AI for narrative synthesis
    5. Package into institutional report format
    """

    def __init__(
        self,
        coinglass_client,
        helsinki_client=None,
        whale_alert_client=None,
        bastion_ai=None,
    ):
        self.coinglass = coinglass_client
        self.helsinki = helsinki_client
        self.whale_alert = whale_alert_client
        self.iros = bastion_ai
        self._report_version = 0

    # =========================================================================
    # MAIN GENERATION ENTRY POINT
    # =========================================================================

    async def generate_institutional_report(
        self,
        symbol: str = "BTC",
        timeframe: str = "4H",
    ) -> Report:
        """
        Generate a full institutional research report for a symbol.

        Returns a Report with sections matching the Goldman-style layout:
        - thesis, conviction, rating
        - key_drivers
        - risks
        - valuation_scenarios (bear/base/bull)
        - trade_structures
        - derivatives_snapshot
        - whale_positioning
        - audit_trail
        """
        logger.info(f"[INSTITUTIONAL] Generating report for {symbol}-PERP")
        gen_start = datetime.utcnow()

        # 1. Fetch all live data in parallel
        quant_data = await self._fetch_all_data(symbol)

        # 2. Build the quant analysis package
        quant_package = self._build_quant_package(symbol, quant_data)

        # 3. Generate AI narrative using BASTION
        narrative = await self._generate_narrative(symbol, quant_package)

        # 4. Compute conviction score and rating
        conviction = self._compute_conviction(quant_package)
        rating = self._compute_rating(conviction, quant_package)
        bias = self._rating_to_bias(rating)

        # 5. Build valuation scenarios
        scenarios = self._build_valuation_scenarios(symbol, quant_package)

        # 6. Build trade structures
        trades = self._build_trade_structures(symbol, quant_package, conviction)

        # 7. Build audit trail
        audit = self._build_audit_trail(gen_start, quant_data)

        # 8. Assemble report
        report_id = f"IR-{symbol}-{datetime.utcnow().strftime('%Y%m%d-%H%M')}"
        self._report_version += 1
        version = f"v{self._report_version}.0"

        price = quant_package.get("price", 0)
        target = scenarios.get("base", {}).get("target", price)
        upside = ((target / price) - 1) * 100 if price > 0 else 0

        title = f"{symbol}-PERP Institutional Research: {RATING_LABELS.get(rating, rating)}"

        summary = narrative.get("thesis", f"{symbol} institutional analysis generated by MCF Labs / BASTION AI engine.")

        confidence_level = Confidence.HIGH if conviction >= 70 else Confidence.MEDIUM if conviction >= 50 else Confidence.LOW

        return Report(
            id=report_id,
            type=ReportType.INSTITUTIONAL_RESEARCH,
            title=title,
            generated_at=datetime.utcnow(),
            bias=bias,
            confidence=confidence_level,
            summary=summary[:500],
            sections={
                # Report metadata
                "report_format": "institutional",
                "version": version,
                "symbol": f"{symbol}-PERP",
                "desk": DESK_MAP.get(symbol, "Macro"),
                "analyst": "MCF Labs AI Engine",
                "published_at": datetime.utcnow().isoformat(),

                # Conviction & Rating
                "conviction": conviction,
                "rating": rating,
                "rating_label": RATING_LABELS.get(rating, rating),
                "rating_history": self._get_rating_history(symbol, rating),
                "target_price": target,
                "current_price": price,
                "upside_percent": round(upside, 1),
                "horizon": "2-5D",

                # Core narrative sections (AI-generated)
                "thesis": narrative.get("thesis", ""),
                "key_drivers": narrative.get("key_drivers", []),
                "risks": narrative.get("risks", []),

                # Valuation
                "valuation_scenarios": scenarios,

                # Trade Structures
                "trade_structures": trades,

                # Derivatives Snapshot
                "derivatives": quant_package.get("derivatives", {}),

                # Whale Intelligence
                "whale_positioning": quant_package.get("whale_analysis", {}),

                # Order Flow
                "order_flow": quant_package.get("order_flow", {}),

                # MCF Ultra Quant Scores
                "mcf_scores": {
                    "composite": quant_package.get("mcf_composite", 0),
                    "structure": quant_package.get("structure_score", 0),
                    "volume": quant_package.get("volume_score", 0),
                    "volatility": quant_package.get("volatility_score", 0),
                    "proximity": quant_package.get("proximity_score", 0),
                    "momentum": quant_package.get("momentum_score", 0),
                    "confluence": quant_package.get("mtf_confluence", 0),
                },

                # Raw data for chart rendering
                "chart_data": quant_package.get("chart_data", {}),

                # Audit Trail
                "audit_trail": audit,
            },
            tags=[
                symbol.lower(),
                "institutional",
                bias.value.lower(),
                f"conviction-{conviction}",
            ],
            data_sources=audit.get("data_sources", []),
        )

    # =========================================================================
    # DATA FETCHING
    # =========================================================================

    async def _fetch_all_data(self, symbol: str) -> Dict[str, Any]:
        """Fetch all data sources in parallel"""
        tasks = {
            "coins_markets": self.coinglass.get_coins_markets(),
            "whale_positions": self.coinglass.get_hyperliquid_whale_positions(symbol),
            "max_pain": self.coinglass.get_options_max_pain(symbol),
            "liquidations": self.coinglass.get_liquidation_coin_list(symbol),
            "funding": self.coinglass.get_funding_rates(symbol),
            "ls_ratio": self.coinglass.get_long_short_ratio(symbol),
            "taker": self.coinglass.get_taker_buy_sell(symbol),
        }

        # Add Helsinki data if available
        if self.helsinki:
            tasks["candles_4h"] = self.helsinki.get_candles(symbol, "4h", 200)
            tasks["candles_1d"] = self.helsinki.get_candles(symbol, "1d", 100)
            tasks["cvd"] = self.helsinki.get_cvd(symbol, "4h")
            tasks["volatility"] = self.helsinki.get_volatility(symbol)

        # Execute all in parallel
        keys = list(tasks.keys())
        results = await asyncio.gather(*tasks.values(), return_exceptions=True)

        data = {}
        for key, result in zip(keys, results):
            if isinstance(result, Exception):
                logger.warning(f"[INSTITUTIONAL] {key} fetch failed: {result}")
                data[key] = None
            else:
                data[key] = result

        return data

    # =========================================================================
    # QUANT ANALYSIS
    # =========================================================================

    def _build_quant_package(self, symbol: str, data: Dict) -> Dict[str, Any]:
        """Build quantitative analysis package from raw data"""
        package = {"symbol": symbol}

        # Current price
        price = self._extract_price(data.get("coins_markets"), symbol)
        package["price"] = price

        # Open Interest
        oi = self._extract_oi(data.get("coins_markets"), symbol)
        package["oi"] = oi

        # Funding rate
        funding = self._extract_funding(data.get("funding"), symbol)
        package["funding"] = funding

        # Long/Short ratio
        ls_ratio = self._extract_ls_ratio(data.get("ls_ratio"))
        package["ls_ratio"] = ls_ratio

        # Max pain
        max_pain = self._extract_max_pain(data.get("max_pain"))
        package["max_pain"] = max_pain

        # Whale analysis
        whale_analysis = self._extract_whale_analysis(data.get("whale_positions"), symbol)
        package["whale_analysis"] = whale_analysis

        # Taker flow
        taker = self._extract_taker_flow(data.get("taker"))
        package["taker_flow"] = taker

        # Liquidation zones
        liq = self._extract_liquidations(data.get("liquidations"), price)
        package["liquidations"] = liq

        # Derivatives snapshot
        package["derivatives"] = {
            "open_interest": oi,
            "funding_rate": funding,
            "long_short_ratio": ls_ratio,
            "max_pain": max_pain,
            "taker_flow": taker,
        }

        # MCF-style scoring (computed from derivatives data)
        scores = self._compute_mcf_scores(package)
        package.update(scores)

        # Order flow analysis
        package["order_flow"] = self._analyze_order_flow(taker, whale_analysis, ls_ratio)

        return package

    def _compute_mcf_scores(self, pkg: Dict) -> Dict[str, float]:
        """
        Compute MCF Ultra-style component scores from live data.

        Returns scores 0-10 for each component + composite.
        """
        scores = {}

        # Structure score: derived from key levels alignment
        price = pkg.get("price", 0)
        max_pain = pkg.get("max_pain", 0)
        if price > 0 and max_pain > 0:
            distance = abs(price - max_pain) / price
            # Closer to max pain = higher structure score
            scores["structure_score"] = round(max(0, 10 - distance * 100), 1)
        else:
            scores["structure_score"] = 5.0

        # Volume score: from taker flow imbalance
        taker = pkg.get("taker_flow", {})
        buy = taker.get("buy", 0)
        sell = taker.get("sell", 0)
        total = buy + sell
        if total > 0:
            imbalance = abs(buy - sell) / total
            scores["volume_score"] = round(5 + imbalance * 10, 1)
        else:
            scores["volume_score"] = 5.0

        # Volatility score: from funding rate (low funding = stable = higher score)
        funding = pkg.get("funding", {})
        rate = abs(funding.get("rate", 0))
        if rate < 0.0001:
            scores["volatility_score"] = 8.0
        elif rate < 0.0003:
            scores["volatility_score"] = 6.5
        elif rate < 0.0005:
            scores["volatility_score"] = 5.0
        else:
            scores["volatility_score"] = 3.0

        # Proximity score: whale positioning conviction
        whales = pkg.get("whale_analysis", {})
        total_long = whales.get("total_long_usd", 0)
        total_short = whales.get("total_short_usd", 0)
        whale_total = total_long + total_short
        if whale_total > 0:
            conviction = abs(total_long - total_short) / whale_total
            scores["proximity_score"] = round(5 + conviction * 5, 1)
        else:
            scores["proximity_score"] = 5.0

        # Momentum score: from LS ratio trend
        ls = pkg.get("ls_ratio", 1.0)
        if ls > 1.2:
            scores["momentum_score"] = 7.5  # Strong long bias
        elif ls > 1.05:
            scores["momentum_score"] = 6.0
        elif ls < 0.8:
            scores["momentum_score"] = 7.5  # Strong short bias (clear direction)
        elif ls < 0.95:
            scores["momentum_score"] = 6.0
        else:
            scores["momentum_score"] = 5.0  # Neutral, unclear

        # MTF Confluence (0-1): multi-signal alignment
        signals_aligned = 0
        total_signals = 5

        whale_bias = "LONG" if total_long > total_short else "SHORT"
        funding_bias = "LONG" if funding.get("rate", 0) < 0 else "SHORT" if funding.get("rate", 0) > 0.0003 else "NEUTRAL"
        ls_bias = "LONG" if ls > 1.05 else "SHORT" if ls < 0.95 else "NEUTRAL"
        taker_bias = "LONG" if buy > sell else "SHORT"
        max_pain_bias = "LONG" if price < max_pain else "SHORT"

        biases = [whale_bias, funding_bias, ls_bias, taker_bias, max_pain_bias]
        long_count = biases.count("LONG")
        short_count = biases.count("SHORT")
        dominant = max(long_count, short_count)

        scores["mtf_confluence"] = round(dominant / total_signals, 2)
        scores["dominant_bias"] = "LONG" if long_count > short_count else "SHORT" if short_count > long_count else "NEUTRAL"

        # Composite MCF score (weighted)
        composite = (
            scores["structure_score"] * 0.30 +
            scores["volume_score"] * 0.20 +
            scores["volatility_score"] * 0.20 +
            scores["proximity_score"] * 0.15 +
            scores["momentum_score"] * 0.15
        )
        scores["mcf_composite"] = round(composite, 1)

        # MCF Grade
        if composite >= 8.5:
            scores["mcf_grade"] = "A+"
        elif composite >= 7.5:
            scores["mcf_grade"] = "A"
        elif composite >= 6.5:
            scores["mcf_grade"] = "B"
        elif composite >= 5.5:
            scores["mcf_grade"] = "C"
        else:
            scores["mcf_grade"] = "D"

        return scores

    def _analyze_order_flow(self, taker: Dict, whales: Dict, ls_ratio: float) -> Dict:
        """Synthesize order flow analysis"""
        buy = taker.get("buy", 0)
        sell = taker.get("sell", 0)
        total = buy + sell

        # CVD direction
        if total > 0:
            buy_pct = buy / total * 100
            if buy_pct > 55:
                cvd_state = "Buying"
            elif buy_pct < 45:
                cvd_state = "Selling"
            else:
                cvd_state = "Neutral"
        else:
            cvd_state = "Unknown"
            buy_pct = 50

        # Whale flow
        whale_bias = whales.get("net_bias", "UNKNOWN")

        return {
            "cvd_state": cvd_state,
            "buy_percent": round(buy_pct, 1),
            "sell_percent": round(100 - buy_pct, 1) if total > 0 else 50,
            "whale_bias": whale_bias,
            "ls_ratio": ls_ratio,
            "flow_bias": "BULLISH" if (cvd_state == "Buying" and whale_bias == "LONG") else
                         "BEARISH" if (cvd_state == "Selling" and whale_bias == "SHORT") else
                         "MIXED",
        }

    # =========================================================================
    # AI NARRATIVE GENERATION
    # =========================================================================

    async def _generate_narrative(self, symbol: str, pkg: Dict) -> Dict[str, Any]:
        """Use BASTION AI to generate the institutional narrative"""

        if not self.iros:
            return self._generate_rule_based_narrative(symbol, pkg)

        prompt = self._build_institutional_prompt(symbol, pkg)

        try:
            result = await self.iros.process_query(
                query=prompt,
                comprehensive=False,
                user_context={"symbol": symbol}
            )

            if result.success and result.response:
                return self._parse_ai_narrative(result.response, symbol, pkg)
            else:
                logger.warning(f"[INSTITUTIONAL] AI narrative failed: {result.error}")
                return self._generate_rule_based_narrative(symbol, pkg)

        except Exception as e:
            logger.error(f"[INSTITUTIONAL] AI narrative error: {e}")
            return self._generate_rule_based_narrative(symbol, pkg)

    def _build_institutional_prompt(self, symbol: str, pkg: Dict) -> str:
        """Build the mega-prompt for institutional report narrative"""

        price = pkg.get("price", 0)
        oi = pkg.get("oi", {})
        funding = pkg.get("funding", {})
        whales = pkg.get("whale_analysis", {})
        taker = pkg.get("taker_flow", {})
        max_pain = pkg.get("max_pain", 0)
        ls_ratio = pkg.get("ls_ratio", 1.0)
        scores = {
            "composite": pkg.get("mcf_composite", 0),
            "structure": pkg.get("structure_score", 0),
            "volume": pkg.get("volume_score", 0),
            "volatility": pkg.get("volatility_score", 0),
            "momentum": pkg.get("momentum_score", 0),
            "confluence": pkg.get("mtf_confluence", 0),
            "grade": pkg.get("mcf_grade", "C"),
        }
        bias = pkg.get("dominant_bias", "NEUTRAL")

        return f"""You are an institutional crypto research analyst at MCF Labs writing a research note for {symbol}-PERP.

LIVE MARKET DATA:
- Price: ${price:,.2f}
- Open Interest: ${oi.get('value', 0)/1e9:.2f}B ({oi.get('change_percent_24h', 0):+.1f}% 24h)
- Funding Rate (8H): {funding.get('rate', 0)*100:.4f}%
- Long/Short Ratio: {ls_ratio:.3f}
- Options Max Pain: ${max_pain:,.0f}
- Taker Buy: ${taker.get('buy', 0)/1e6:.0f}M / Sell: ${taker.get('sell', 0)/1e6:.0f}M

WHALE POSITIONING (Hyperliquid):
- Net Bias: {whales.get('net_bias', 'UNKNOWN')}
- Longs: ${whales.get('total_long_usd', 0)/1e6:.1f}M
- Shorts: ${whales.get('total_short_usd', 0)/1e6:.1f}M
- Positions: {whales.get('position_count', 0)}

MCF ULTRA SCORES:
- Composite: {scores['composite']}/10 (Grade {scores['grade']})
- Structure: {scores['structure']}/10
- Volume: {scores['volume']}/10
- Volatility: {scores['volatility']}/10
- Momentum: {scores['momentum']}/10
- Multi-Signal Confluence: {scores['confluence']*100:.0f}%
- Dominant Bias: {bias}

WRITE AN INSTITUTIONAL RESEARCH NOTE. Return your response in this EXACT format:

THESIS: [2-4 sentences describing the investment thesis. Reference specific data points. Include the key price zone you're watching.]

DRIVER_1: [Key driver with specific data point and source]
DRIVER_2: [Second key driver]
DRIVER_3: [Third key driver]

RISK_1: [Primary risk with specific correlation or metric]
RISK_2: [Secondary risk]

Be specific with numbers. Write like a hedge fund analyst. Reference the data I gave you."""

    def _parse_ai_narrative(self, response: str, symbol: str, pkg: Dict) -> Dict:
        """Parse AI response into structured narrative sections"""
        thesis = ""
        drivers = []
        risks = []

        lines = response.strip().split("\n")

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith("THESIS:"):
                thesis = line.replace("THESIS:", "").strip()
            elif line.startswith("DRIVER_"):
                driver_text = line.split(":", 1)[-1].strip() if ":" in line else line
                if driver_text:
                    drivers.append({
                        "text": driver_text,
                        "source": self._extract_source(driver_text),
                        "time": self._extract_time(driver_text),
                    })
            elif line.startswith("RISK_"):
                risk_text = line.split(":", 1)[-1].strip() if ":" in line else line
                if risk_text:
                    risks.append({
                        "text": risk_text,
                        "severity": "HIGH" if any(w in risk_text.lower() for w in ["liquidation", "crash", "extreme"]) else "MEDIUM",
                    })

        # Fallback if parsing failed
        if not thesis:
            thesis = response[:500] if len(response) > 500 else response

        if not drivers:
            drivers = self._generate_default_drivers(symbol, pkg)

        if not risks:
            risks = self._generate_default_risks(symbol, pkg)

        return {"thesis": thesis, "key_drivers": drivers, "risks": risks}

    def _extract_source(self, text: str) -> str:
        """Extract data source from driver text"""
        sources = ["Coinglass", "Hyperliquid", "Whale Alert", "Helsinki", "Deribit", "Binance", "OKX"]
        for s in sources:
            if s.lower() in text.lower():
                return s
        return "MCF Analytics"

    def _extract_time(self, text: str) -> str:
        """Extract time reference from driver text"""
        for pattern in ["24h", "4h", "1h", "8h", "12h", "1d", "7d"]:
            if pattern in text.lower():
                return pattern
        return "live"

    def _generate_rule_based_narrative(self, symbol: str, pkg: Dict) -> Dict:
        """Generate narrative without AI (rule-based fallback)"""
        price = pkg.get("price", 0)
        bias = pkg.get("dominant_bias", "NEUTRAL")
        whales = pkg.get("whale_analysis", {})
        funding = pkg.get("funding", {})
        max_pain = pkg.get("max_pain", 0)
        ls_ratio = pkg.get("ls_ratio", 1.0)
        oi = pkg.get("oi", {})
        scores = pkg.get("mcf_composite", 5.0)

        # Build thesis
        whale_side = whales.get("net_bias", "neutral")
        total_long = whales.get("total_long_usd", 0)
        total_short = whales.get("total_short_usd", 0)

        if bias == "LONG":
            thesis = (
                f"{symbol} shows constructive structure with {whale_side.lower()} whale positioning and "
                f"favorable derivatives alignment. Funding remains {'neutral' if abs(funding.get('rate', 0)) < 0.0002 else 'elevated'} "
                f"at {funding.get('rate', 0)*100:.4f}%, suggesting room for continuation. "
                f"We expect a move toward the ${max_pain:,.0f} max pain zone as short positions face increasing pressure."
            )
        elif bias == "SHORT":
            thesis = (
                f"{symbol} derivatives structure signals distribution with {whale_side.lower()} whale bias dominating. "
                f"Open interest {'expansion' if oi.get('change_percent_24h', 0) > 0 else 'contraction'} alongside "
                f"{'elevated' if funding.get('rate', 0) > 0.0003 else 'neutral'} funding suggests overleveraged longs. "
                f"We anticipate a correction toward ${max_pain:,.0f} max pain with long liquidation cascades accelerating the move."
            )
        else:
            thesis = (
                f"{symbol} is consolidating near ${price:,.0f} with mixed signals across derivatives metrics. "
                f"Whale positioning is balanced (${total_long/1e6:.0f}M long vs ${total_short/1e6:.0f}M short) "
                f"and funding is neutral. Expect range-bound action until a catalyst emerges. "
                f"Key breakout level: ${max_pain:,.0f} max pain."
            )

        drivers = self._generate_default_drivers(symbol, pkg)
        risks = self._generate_default_risks(symbol, pkg)

        return {"thesis": thesis, "key_drivers": drivers, "risks": risks}

    def _generate_default_drivers(self, symbol: str, pkg: Dict) -> List[Dict]:
        """Generate default key drivers from data"""
        drivers = []
        whales = pkg.get("whale_analysis", {})
        funding = pkg.get("funding", {})
        oi = pkg.get("oi", {})
        taker = pkg.get("taker_flow", {})

        # Whale positioning
        total_long = whales.get("total_long_usd", 0)
        total_short = whales.get("total_short_usd", 0)
        dominant = "long" if total_long > total_short else "short"
        drivers.append({
            "text": f"Hyperliquid whale {dominant} exposure ${max(total_long, total_short)/1e6:.0f}M vs ${min(total_long, total_short)/1e6:.0f}M — {whales.get('position_count', 0)} tracked positions",
            "source": "Hyperliquid",
            "time": "live",
        })

        # OI change
        oi_change = oi.get("change_percent_24h", 0)
        if abs(oi_change) > 1:
            drivers.append({
                "text": f"Open interest {'expanding' if oi_change > 0 else 'contracting'} {oi_change:+.1f}% in 24h — {'new money entering' if oi_change > 0 else 'positions closing'}",
                "source": "Coinglass",
                "time": "24h",
            })

        # Funding signal
        rate = funding.get("rate", 0)
        if abs(rate) > 0.0001:
            direction = "positive (longs pay)" if rate > 0 else "negative (shorts pay)"
            drivers.append({
                "text": f"Funding rate {direction} at {rate*100:.4f}% — {'crowded long' if rate > 0.0003 else 'crowded short' if rate < -0.0002 else 'moderate'} positioning",
                "source": "Coinglass",
                "time": "8h",
            })

        # Taker flow
        buy = taker.get("buy", 0)
        sell = taker.get("sell", 0)
        if buy + sell > 0:
            dominant_flow = "buy" if buy > sell else "sell"
            drivers.append({
                "text": f"Taker {dominant_flow} flow dominant — ${buy/1e6:.0f}M bought vs ${sell/1e6:.0f}M sold",
                "source": "Coinglass",
                "time": "24h",
            })

        return drivers[:3]  # Max 3 drivers

    def _generate_default_risks(self, symbol: str, pkg: Dict) -> List[Dict]:
        """Generate default risk factors"""
        risks = []
        funding = pkg.get("funding", {})
        whales = pkg.get("whale_analysis", {})

        # Funding risk
        rate = funding.get("rate", 0)
        if abs(rate) > 0.0003:
            risks.append({
                "text": f"Elevated funding ({rate*100:.4f}%) — crowded positioning increases squeeze risk",
                "severity": "HIGH",
            })

        # Whale liquidation risk
        total_long = whales.get("total_long_usd", 0)
        total_short = whales.get("total_short_usd", 0)
        if max(total_long, total_short) > 200e6:
            side = "long" if total_long > total_short else "short"
            risks.append({
                "text": f"Large whale {side} concentration (${max(total_long, total_short)/1e6:.0f}M) — cascade liquidation risk if price moves against",
                "severity": "HIGH",
            })

        # General BTC correlation risk
        if symbol != "BTC":
            risks.append({
                "text": f"BTC correlation risk — {symbol} tracks BTC 4H moves (Correlation: 0.80+)",
                "severity": "MEDIUM",
            })

        # Market structure risk
        risks.append({
            "text": "Weekend/low-liquidity sessions amplify volatility — position sizing must account for gaps",
            "severity": "MEDIUM",
        })

        return risks[:2]  # Max 2 risks

    # =========================================================================
    # CONVICTION & RATING
    # =========================================================================

    def _compute_conviction(self, pkg: Dict) -> int:
        """
        Compute conviction score (0-100%).

        Weights:
        - MCF Composite: 40%
        - Whale alignment: 20%
        - Derivatives alignment: 20%
        - Multi-signal confluence: 20%
        """
        mcf = pkg.get("mcf_composite", 5.0) * 10  # Scale 0-100

        # Whale conviction
        whales = pkg.get("whale_analysis", {})
        total_long = whales.get("total_long_usd", 0)
        total_short = whales.get("total_short_usd", 0)
        whale_total = total_long + total_short
        whale_conviction = abs(total_long - total_short) / whale_total * 100 if whale_total > 0 else 50

        # Derivatives alignment
        funding_ok = abs(pkg.get("funding", {}).get("rate", 0)) < 0.0005
        oi_expanding = pkg.get("oi", {}).get("change_percent_24h", 0) > 0
        deriv_score = (50 if funding_ok else 30) + (25 if oi_expanding else 0)

        # Confluence
        confluence = pkg.get("mtf_confluence", 0.5) * 100

        conviction = int(
            mcf * 0.40 +
            whale_conviction * 0.20 +
            deriv_score * 0.20 +
            confluence * 0.20
        )

        return min(99, max(15, conviction))

    def _compute_rating(self, conviction: int, pkg: Dict) -> str:
        """Compute analyst rating from conviction"""
        bias = pkg.get("dominant_bias", "NEUTRAL")

        if conviction >= 80:
            return "STRONG_BUY" if bias == "LONG" else "STRONG_SELL"
        elif conviction >= 65:
            return "BUY" if bias == "LONG" else "SELL"
        elif conviction >= 45:
            return "HOLD"
        else:
            return "SELL" if bias == "LONG" else "BUY"  # Contrarian at low conviction

    def _rating_to_bias(self, rating: str) -> Bias:
        if rating in ["STRONG_BUY", "BUY"]:
            return Bias.BULLISH
        elif rating in ["STRONG_SELL", "SELL"]:
            return Bias.BEARISH
        return Bias.NEUTRAL

    def _get_rating_history(self, symbol: str, current_rating: str) -> List[Dict]:
        """Build rating history (for now, just current)"""
        label = RATING_LABELS.get(current_rating, current_rating)
        return [
            {
                "date": datetime.utcnow().strftime("%Y-%m-%d"),
                "from": "Neutral",
                "to": label,
            }
        ]

    # =========================================================================
    # VALUATION SCENARIOS
    # =========================================================================

    def _build_valuation_scenarios(self, symbol: str, pkg: Dict) -> Dict:
        """Build Bear/Base/Bull valuation scenarios"""
        price = pkg.get("price", 0)
        max_pain = pkg.get("max_pain", 0)
        liq = pkg.get("liquidations", {})
        bias = pkg.get("dominant_bias", "NEUTRAL")

        if price <= 0:
            return {}

        # Support/resistance from liquidation zones
        support = liq.get("longs", {}).get("price", price * 0.95)
        resistance = liq.get("shorts", {}).get("price", price * 1.05)

        if bias == "LONG":
            bear_target = support
            base_target = max_pain if max_pain > price else price * 1.05
            bull_target = resistance * 1.05
        elif bias == "SHORT":
            bear_target = support * 0.95
            base_target = max_pain if max_pain < price else price * 0.95
            bull_target = resistance
        else:
            bear_target = support
            base_target = price
            bull_target = resistance

        return {
            "bear": {
                "target": round(bear_target, 2),
                "probability": 20 if bias == "LONG" else 40 if bias == "SHORT" else 30,
                "label": "Bear",
            },
            "base": {
                "target": round(base_target, 2),
                "probability": 50,
                "label": "Base",
            },
            "bull": {
                "target": round(bull_target, 2),
                "probability": 40 if bias == "LONG" else 20 if bias == "SHORT" else 30,
                "label": "Bull",
            },
            "rationale": f"Base case assumes {'continuation of current trend' if bias != 'NEUTRAL' else 'range-bound action'} with max pain at ${max_pain:,.0f}.",
        }

    # =========================================================================
    # TRADE STRUCTURES
    # =========================================================================

    def _build_trade_structures(self, symbol: str, pkg: Dict, conviction: int) -> List[Dict]:
        """Build tactical trade structures"""
        price = pkg.get("price", 0)
        scenarios = self._build_valuation_scenarios(symbol, pkg)
        bias = pkg.get("dominant_bias", "NEUTRAL")
        max_pain = pkg.get("max_pain", 0)

        if price <= 0:
            return []

        trades = []

        if bias == "LONG":
            # Momentum trade
            entry = round(price * 1.002, 2)
            target = scenarios.get("bull", {}).get("target", price * 1.10)
            stop = round(price * 0.97, 2)
            rr = round(abs(target - entry) / abs(entry - stop), 2) if abs(entry - stop) > 0 else 0

            trades.append({
                "type": "MOMENTUM",
                "direction": "LONG",
                "entry": entry,
                "target": round(target, 2),
                "stop": stop,
                "size": "Aggressive (1.5%)" if conviction >= 70 else "Standard (1.0%)",
                "risk_reward": rr,
                "status": "QUEUE" if conviction >= 60 else "WAIT",
            })

            # Pullback trade
            pb_entry = round(price * 0.985, 2)
            pb_target = round(max_pain if max_pain > price else price * 1.06, 2)
            pb_stop = round(price * 0.965, 2)
            pb_rr = round(abs(pb_target - pb_entry) / abs(pb_entry - pb_stop), 2) if abs(pb_entry - pb_stop) > 0 else 0

            trades.append({
                "type": "PULLBACK",
                "direction": "LONG",
                "entry": pb_entry,
                "target": pb_target,
                "stop": pb_stop,
                "size": "House (1.0%)",
                "risk_reward": pb_rr,
                "status": "WAIT",
            })

        elif bias == "SHORT":
            entry = round(price * 0.998, 2)
            target = scenarios.get("bear", {}).get("target", price * 0.90)
            stop = round(price * 1.03, 2)
            rr = round(abs(entry - target) / abs(stop - entry), 2) if abs(stop - entry) > 0 else 0

            trades.append({
                "type": "MOMENTUM",
                "direction": "SHORT",
                "entry": entry,
                "target": round(target, 2),
                "stop": stop,
                "size": "Aggressive (1.5%)" if conviction >= 70 else "Standard (1.0%)",
                "risk_reward": rr,
                "status": "QUEUE" if conviction >= 60 else "WAIT",
            })

            # Fade trade
            fade_entry = round(price * 1.015, 2)
            fade_target = round(max_pain if max_pain < price else price * 0.94, 2)
            fade_stop = round(price * 1.035, 2)
            fade_rr = round(abs(fade_entry - fade_target) / abs(fade_stop - fade_entry), 2) if abs(fade_stop - fade_entry) > 0 else 0

            trades.append({
                "type": "FADE",
                "direction": "SHORT",
                "entry": fade_entry,
                "target": fade_target,
                "stop": fade_stop,
                "size": "House (1.0%)",
                "risk_reward": fade_rr,
                "status": "WAIT",
            })

        return trades

    # =========================================================================
    # AUDIT TRAIL
    # =========================================================================

    def _build_audit_trail(self, gen_start: datetime, data: Dict) -> Dict:
        """Build audit trail for compliance"""
        gen_end = datetime.utcnow()
        duration_ms = int((gen_end - gen_start).total_seconds() * 1000)

        # Track which data sources succeeded
        sources = []
        for key, val in data.items():
            if val is not None:
                if key.startswith("candles") or key in ("cvd", "volatility"):
                    sources.append("helsinki")
                elif key == "whale_positions":
                    sources.append("hyperliquid")
                else:
                    sources.append("coinglass")

        sources = list(set(sources))

        return {
            "generated_at": gen_end.isoformat(),
            "generation_time_ms": duration_ms,
            "data_sources": sources,
            "model": "BASTION-32B" if self.iros else "Rule-Based",
            "engine": "MCF Ultra v3.0",
            "versions": [
                {
                    "version": "v1.0",
                    "status": "Published",
                    "author": "MCF Labs AI Engine",
                    "approved_by": "Compliance_AI",
                    "time": gen_end.strftime("%I:%M %p"),
                },
            ],
        }

    # =========================================================================
    # DATA EXTRACTION HELPERS
    # =========================================================================

    def _extract_price(self, data, symbol: str) -> float:
        if not data or not hasattr(data, 'success') or not data.success:
            return 0
        coins = data.data if isinstance(data.data, list) else []
        for coin in coins:
            if coin.get("symbol", "").upper() == symbol.upper():
                return coin.get("price", 0)
        return 0

    def _extract_oi(self, data, symbol: str) -> Dict:
        if not data or not hasattr(data, 'success') or not data.success:
            return {"value": 0, "change_24h": 0, "change_percent_24h": 0}
        coins = data.data if isinstance(data.data, list) else []
        for coin in coins:
            if coin.get("symbol", "").upper() == symbol.upper():
                return {
                    "value": coin.get("openInterest", 0),
                    "change_24h": coin.get("oiChg24h", 0) or 0,
                    "change_percent_24h": coin.get("oiChgPercent24h", 0) or coin.get("oiChg24hPercent", 0) or 0,
                }
        return {"value": 0, "change_24h": 0, "change_percent_24h": 0}

    def _extract_funding(self, data, symbol: str) -> Dict:
        result = {"rate": 0, "exchange_rates": []}
        if not data or not hasattr(data, 'success') or not data.success:
            return result

        rates = []
        if isinstance(data.data, dict):
            for key in ("usdtOrUsdMarginList", "tokenMarginList"):
                for item in data.data.get(key, []):
                    rate = item.get("rate", 0) or item.get("fundingRate", 0)
                    if rate:
                        rates.append({"exchange": item.get("exchangeName", "?"), "rate": rate})
        elif isinstance(data.data, list):
            for item in data.data:
                rate = item.get("rate", 0) or item.get("fundingRate", 0)
                if rate:
                    rates.append({"exchange": item.get("exchangeName", "?"), "rate": rate})

        if rates:
            avg = sum(r["rate"] for r in rates) / len(rates)
            return {"rate": avg, "exchange_rates": rates[:5], "avg_rate": avg}
        return result

    def _extract_ls_ratio(self, data) -> float:
        if data and hasattr(data, 'success') and data.success and data.data:
            if isinstance(data.data, list) and len(data.data) > 0:
                return data.data[-1].get("longShortRatio", 1.0)
        return 1.0

    def _extract_max_pain(self, data) -> float:
        if data and hasattr(data, 'success') and data.success and data.data:
            if isinstance(data.data, list) and len(data.data) > 0:
                return data.data[0].get("maxPain", 0)
        return 0

    def _extract_whale_analysis(self, data, symbol: str) -> Dict:
        if not data or not hasattr(data, 'success') or not data.success:
            return {"net_bias": "UNKNOWN", "total_long_usd": 0, "total_short_usd": 0, "position_count": 0}

        positions = data.data if isinstance(data.data, list) else []
        if symbol:
            positions = [p for p in positions if p.get("symbol", "").upper() == symbol.upper()]

        total_long = sum(abs(p.get("positionValueUsd", 0)) for p in positions if p.get("positionSize", 0) > 0)
        total_short = sum(abs(p.get("positionValueUsd", 0)) for p in positions if p.get("positionSize", 0) < 0)

        return {
            "net_bias": "LONG" if total_long > total_short else "SHORT",
            "total_long_usd": total_long,
            "total_short_usd": total_short,
            "position_count": len(positions),
        }

    def _extract_taker_flow(self, data) -> Dict:
        if not data or not hasattr(data, 'success') or not data.success:
            return {"buy": 0, "sell": 0}
        if isinstance(data.data, list):
            return {
                "buy": sum(t.get("buyVolUsd", 0) for t in data.data),
                "sell": sum(t.get("sellVolUsd", 0) for t in data.data),
            }
        return {"buy": 0, "sell": 0}

    def _extract_liquidations(self, data, price: float) -> Dict:
        return {
            "longs": {"price": round(price * 0.95, 2), "usd": 0},
            "shorts": {"price": round(price * 1.05, 2), "usd": 0},
        }


# =========================================================================
# FACTORY
# =========================================================================

def create_institutional_generator(
    coinglass_client,
    helsinki_client=None,
    whale_alert_client=None,
    model_url: str = None,
    model_api_key: str = None,
) -> InstitutionalReportGenerator:
    """Create an institutional report generator instance"""
    bastion_ai = None

    if model_url:
        try:
            from iros_integration.services.bastion_ai import BastionAI
            bastion_ai = BastionAI(
                helsinki_url=helsinki_client.base_url if helsinki_client else None,
                model_url=model_url,
                model_api_key=model_api_key,
            )
            logger.info(f"[INSTITUTIONAL] BastionAI initialized: {model_url}")
        except Exception as e:
            logger.warning(f"[INSTITUTIONAL] BastionAI init failed: {e}")

    return InstitutionalReportGenerator(
        coinglass_client=coinglass_client,
        helsinki_client=helsinki_client,
        whale_alert_client=whale_alert_client,
        bastion_ai=bastion_ai,
    )
