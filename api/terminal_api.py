"""
BASTION Terminal API
=====================
Full API for the Trading Terminal - connects all IROS intelligence
"""

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from contextlib import asynccontextmanager
import asyncio
import json
import time
import random
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import sys
import logging

# Setup logging FIRST
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add paths - handle both local and Vercel environments
try:
    bastion_path = Path(__file__).parent.parent.resolve()
except:
    bastion_path = Path.cwd()

sys.path.insert(0, str(bastion_path))

# For Vercel, also try the /var/task path
if not (bastion_path / "iros_integration").exists():
    vercel_path = Path("/var/task")
    if (vercel_path / "iros_integration").exists():
        bastion_path = vercel_path
        sys.path.insert(0, str(vercel_path))

logger.info(f"BASTION path: {bastion_path}")

# Import IROS integration - with fallbacks for serverless
try:
    from iros_integration.services.helsinki import HelsinkiClient
    from iros_integration.services.query_processor import QueryProcessor
    from iros_integration.services.whale_alert import WhaleAlertClient
    from iros_integration.services.coinglass import CoinglassClient, CoinglassResponse
    from iros_integration.services.exchange_connector import user_context, Position
    logger.info("IROS integration modules loaded successfully")
except ImportError as e:
    logger.error(f"Import error: {e}")
    # Create dummy classes for graceful degradation
    class HelsinkiClient:
        async def fetch_full_data(self, *args, **kwargs): return {}
    class QueryProcessor:
        def extract_context(self, *args, **kwargs): return type('obj', (object,), {'symbol': 'BTC', 'capital': 10000, 'timeframe': '1h', 'query_intent': 'analysis'})()
    class WhaleAlertClient:
        async def get_recent_transactions(self, *args, **kwargs): return []
    class CoinglassClient:
        async def get_liquidation_history(self, *args, **kwargs): return type('obj', (object,), {'success': False, 'data': None})()
        async def get_open_interest(self, *args, **kwargs): return type('obj', (object,), {'success': False, 'data': None})()
        async def get_funding_rates(self, *args, **kwargs): return type('obj', (object,), {'success': False, 'data': None})()
        async def get_long_short_ratio(self, *args, **kwargs): return type('obj', (object,), {'success': False, 'data': None})()
    class CoinglassResponse:
        success: bool = False
        data = None
    class Position:
        pass
    user_context = type('obj', (object,), {
        'get_all_positions': lambda: [],
        'get_position_context_for_ai': lambda x: ''
    })()

# Global clients
helsinki: HelsinkiClient = None
query_processor: QueryProcessor = None
whale_alert: WhaleAlertClient = None
coinglass: CoinglassClient = None

# Global scheduler
mcf_scheduler = None

# WebSocket connections
active_connections: List[WebSocket] = []

# Price cache - reduced TTL for high-frequency mode (300 req/min tier)
price_cache: Dict[str, Any] = {}
cache_ttl = 2  # seconds (was 10, now faster for premium tier)

# Mock position data (will be replaced with real session data)
MOCK_POSITIONS = [
    {
        "id": "pos_btc_001",
        "symbol": "BTC-PERP",
        "direction": "long",
        "entry_price": 95120,
        "current_price": 96847,
        "size": 0.45,
        "pnl_pct": 1.82,
        "r_multiple": 2.4,
        "stop": 94180,
        "targets": [
            {"price": 96800, "hit": True, "label": "T1"},
            {"price": 98200, "hit": False, "label": "T2"},
        ],
        "trailing": {"active": True, "price": 96412, "slope": 2.3},
        "status": "trailing"
    },
    {
        "id": "pos_eth_001",
        "symbol": "ETH-PERP",
        "direction": "short",
        "entry_price": 3245,
        "current_price": 3198,
        "size": 5.2,
        "pnl_pct": 1.47,
        "r_multiple": 0.8,
        "stop": 3312,
        "guard": {"active": True, "price": 3287},
        "targets": [
            {"price": 3100, "hit": False, "label": "T1"},
        ],
        "status": "guarding"
    },
    {
        "id": "pos_sol_001",
        "symbol": "SOL-PERP",
        "direction": "long",
        "entry_price": 142.80,
        "current_price": 141.20,
        "size": 50,
        "pnl_pct": -1.12,
        "r_multiple": -0.3,
        "stop": 140.10,
        "targets": [],
        "status": "at_risk"
    }
]


def init_clients():
    """Initialize clients lazily for serverless compatibility."""
    global helsinki, query_processor, whale_alert, coinglass
    
    if helsinki is None:
        try:
            helsinki = HelsinkiClient()
            logger.info("Helsinki VM client ready")
        except Exception as e:
            logger.error(f"Helsinki init error: {e}")
    
    if query_processor is None:
        try:
            query_processor = QueryProcessor()
            logger.info("Query processor ready")
        except Exception as e:
            logger.error(f"Query processor init error: {e}")
    
    if whale_alert is None:
        try:
            whale_alert = WhaleAlertClient()
            logger.info("Whale Alert client ready")
        except Exception as e:
            logger.error(f"Whale Alert init error: {e}")
    
    if coinglass is None:
        try:
            coinglass = CoinglassClient()
            logger.info("Coinglass client ready")
        except Exception as e:
            logger.error(f"Coinglass init error: {e}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown."""
    global mcf_scheduler
    logger.info("BASTION Terminal API starting...")
    init_clients()
    
    # Start MCF Labs report scheduler
    try:
        from mcf_labs.scheduler import start_scheduler, stop_scheduler
        model_url = os.getenv("BASTION_MODEL_URL")
        model_api_key = os.getenv("BASTION_MODEL_API_KEY", "")
        
        if coinglass and model_url:
            mcf_scheduler = await start_scheduler(
                coinglass_client=coinglass,
                helsinki_client=helsinki,
                whale_alert_client=whale_alert,
                use_iros=True,
                model_url=model_url,
                model_api_key=model_api_key
            )
            logger.info("[MCF] Report scheduler started - auto-generating reports")
        else:
            logger.warning("[MCF] Scheduler not started - missing coinglass or model_url")
    except Exception as e:
        logger.error(f"[MCF] Failed to start scheduler: {e}")
    
    logger.info("BASTION Terminal API LIVE")
    yield
    
    # Stop scheduler on shutdown
    try:
        from mcf_labs.scheduler import stop_scheduler
        await stop_scheduler()
        logger.info("[MCF] Report scheduler stopped")
    except Exception as e:
        logger.error(f"[MCF] Error stopping scheduler: {e}")
    
    logger.info("BASTION Terminal API shutting down...")


app = FastAPI(
    title="BASTION Terminal API",
    description="Powers the BASTION Trading Terminal",
    version="1.0.0",
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# =============================================================================
# STATUS & HEALTH CHECK
# =============================================================================

@app.get("/api/status")
async def get_status():
    """Health check and client status."""
    # Lazy init on first request
    try:
        init_clients()
    except Exception as e:
        logger.error(f"Init error: {e}")
    
    try:
        cfg_info = {
            "coinglass_key_set": bool(getattr(config, 'coinglass', None) and config.coinglass.api_key),
            "whale_key_set": bool(getattr(config, 'whale_alert', None) and config.whale_alert.api_key),
            "helsinki_url": getattr(config.helsinki, 'base_url', 'not set') if hasattr(config, 'helsinki') else "not set"
        }
    except:
        cfg_info = {"error": "config access failed"}
    
    return {
        "status": "ok",
        "helsinki": helsinki is not None,
        "coinglass": coinglass is not None,
        "whale_alert": whale_alert is not None,
        "bastion_path": str(bastion_path),
        "config": cfg_info
    }


@app.get("/api/health")
async def health_check():
    """Simple health check - no client init."""
    return {"status": "ok"}


@app.get("/api/iros-test")
async def test_iros_connection():
    """Test IROS model connection directly."""
    import httpx
    
    model_url = os.getenv("BASTION_MODEL_URL")
    model_api_key = os.getenv("BASTION_MODEL_API_KEY", "")
    
    if not model_url:
        return {"success": False, "error": "BASTION_MODEL_URL not set", "url": None}
    
    results = {"url": model_url, "tests": {}}
    
    # Test 1: Can we reach the models endpoint?
    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            resp = await client.get(f"{model_url}/v1/models")
            results["tests"]["models_endpoint"] = {
                "status": resp.status_code,
                "success": resp.status_code == 200,
                "body_preview": resp.text[:200] if resp.status_code == 200 else resp.text
            }
    except Exception as e:
        results["tests"]["models_endpoint"] = {"success": False, "error": str(e)}
    
    # Test 2: Can we do a chat completion?
    try:
        headers = {"Content-Type": "application/json"}
        if model_api_key:
            headers["Authorization"] = f"Bearer {model_api_key}"
            
        async with httpx.AsyncClient(timeout=30.0) as client:
            resp = await client.post(
                f"{model_url}/v1/chat/completions",
                headers=headers,
                json={
                    "model": "iros",
                    "messages": [{"role": "user", "content": "test"}],
                    "max_tokens": 10
                }
            )
            results["tests"]["chat_completion"] = {
                "status": resp.status_code,
                "success": resp.status_code == 200,
                "body_preview": resp.text[:300]
            }
    except Exception as e:
        results["tests"]["chat_completion"] = {"success": False, "error": str(e)}
    
    results["success"] = all(t.get("success", False) for t in results["tests"].values())
    return results


# =============================================================================
# TERMINAL PAGE
# =============================================================================

@app.get("/", response_class=HTMLResponse)
async def serve_terminal():
    """Serve the terminal page."""
    terminal_path = bastion_path / "generated-page.html"
    if terminal_path.exists():
        return FileResponse(terminal_path)
    return HTMLResponse("<h1>Terminal not found</h1>")


@app.get("/frontend", response_class=HTMLResponse)
async def serve_frontend():
    """Serve the frontend landing page."""
    frontend_path = bastion_path / "BASTION FRONT END.html"
    if frontend_path.exists():
        return FileResponse(frontend_path)
    return HTMLResponse("<h1>Frontend not found</h1>")


@app.get("/visualizations", response_class=HTMLResponse)
async def serve_visualizations():
    """Serve the 3D visualizations page."""
    viz_path = bastion_path / "web" / "visualizations.html"
    if viz_path.exists():
        return FileResponse(viz_path)
    return HTMLResponse("<h1>Visualizations page not found</h1>")


@app.get("/research", response_class=HTMLResponse)
async def serve_research():
    """Serve the Research Terminal page."""
    research_path = bastion_path / "web" / "research.html"
    if research_path.exists():
        return FileResponse(research_path)
    return HTMLResponse("<h1>Research page not found</h1>")


@app.get("/account", response_class=HTMLResponse)
async def serve_account():
    """Serve the Account Center page."""
    account_path = bastion_path / "web" / "account.html"
    if account_path.exists():
        return FileResponse(account_path)
    return HTMLResponse("<h1>Account page not found</h1>")


# =============================================================================
# EXCHANGE API KEY MANAGEMENT
# =============================================================================

# In-memory storage for demo (would use encrypted DB in production)
connected_exchanges: Dict[str, Dict] = {}


@app.post("/api/exchange/connect")
async def connect_exchange(data: dict):
    """Connect a new exchange via API keys."""
    exchange = data.get("exchange")
    api_key = data.get("api_key")
    api_secret = data.get("api_secret")
    passphrase = data.get("passphrase")
    read_only = data.get("read_only", True)
    
    if not exchange or not api_key or not api_secret:
        raise HTTPException(status_code=400, detail="Missing required fields")
    
    # Validate exchange name
    valid_exchanges = ["blofin", "bitunix", "bybit", "okx", "binance", "deribit"]
    if exchange not in valid_exchanges:
        raise HTTPException(status_code=400, detail=f"Invalid exchange: {exchange}")
    
    # Try to connect using the exchange connector service
    try:
        success = await user_context.connect_exchange(
            exchange=exchange,
            api_key=api_key,
            api_secret=api_secret,
            passphrase=passphrase,
            read_only=read_only
        )
        
        if not success:
            # Still store for demo mode even if connection fails
            logger.warning(f"[EXCHANGE] Connection test failed for {exchange}, storing in demo mode")
    except Exception as e:
        logger.warning(f"[EXCHANGE] Connection error: {e}, storing in demo mode")
    
    # Store connection info (masked)
    connected_exchanges[exchange] = {
        "exchange": exchange,
        "api_key": api_key[:8] + "..." + api_key[-4:] if len(api_key) > 12 else "***",
        "read_only": read_only,
        "connected_at": datetime.now().isoformat(),
        "status": "active"
    }
    
    logger.info(f"[EXCHANGE] Connected to {exchange}")
    
    return {
        "success": True,
        "message": f"Successfully connected to {exchange}",
        "exchange": connected_exchanges[exchange]
    }


@app.get("/api/exchange/list")
async def list_exchanges():
    """List all connected exchanges."""
    return {
        "success": True,
        "exchanges": list(connected_exchanges.values())
    }


@app.delete("/api/exchange/{exchange_name}")
async def disconnect_exchange(exchange_name: str):
    """Disconnect an exchange."""
    if exchange_name not in connected_exchanges:
        raise HTTPException(status_code=404, detail="Exchange not connected")
    
    del connected_exchanges[exchange_name]
    logger.info(f"[EXCHANGE] Disconnected from {exchange_name}")
    
    return {"success": True, "message": f"Disconnected from {exchange_name}"}


@app.get("/api/exchange/{exchange_name}/positions")
async def get_exchange_positions(exchange_name: str):
    """Get live positions from a connected exchange."""
    if exchange_name not in connected_exchanges:
        raise HTTPException(status_code=404, detail="Exchange not connected")
    
    # Try to get live positions
    try:
        all_positions = await user_context.get_all_positions()
        exchange_positions = [
            {
                "id": p.id,
                "symbol": p.symbol,
                "direction": p.direction,
                "entry_price": p.entry_price,
                "current_price": p.current_price,
                "size": p.size,
                "size_usd": p.size_usd,
                "pnl": p.pnl,
                "pnl_pct": p.pnl_pct,
                "leverage": p.leverage,
                "liquidation_price": p.liquidation_price,
                "stop_loss": p.stop_loss,
                "take_profit": p.take_profit,
                "exchange": p.exchange,
                "updated_at": p.updated_at
            }
            for p in all_positions if p.exchange == exchange_name
        ]
        
        if exchange_positions:
            return {
                "success": True,
                "exchange": exchange_name,
                "positions": exchange_positions,
                "timestamp": datetime.now().isoformat(),
                "source": "live"
            }
    except Exception as e:
        logger.warning(f"Could not fetch live positions: {e}")
    
    # Fallback to mock data
    return {
        "success": True,
        "exchange": exchange_name,
        "positions": MOCK_POSITIONS,
        "timestamp": datetime.now().isoformat(),
        "source": "demo"
    }


@app.get("/api/positions/all")
async def get_all_positions():
    """Get positions from all connected exchanges."""
    try:
        all_positions = await user_context.get_all_positions()
        
        if all_positions:
            return {
                "success": True,
                "positions": [
                    {
                        "id": p.id,
                        "symbol": p.symbol,
                        "direction": p.direction,
                        "entry_price": p.entry_price,
                        "current_price": p.current_price,
                        "size": p.size,
                        "size_usd": p.size_usd,
                        "pnl": p.pnl,
                        "pnl_pct": p.pnl_pct,
                        "leverage": p.leverage,
                        "liquidation_price": p.liquidation_price,
                        "exchange": p.exchange,
                        "updated_at": p.updated_at
                    }
                    for p in all_positions
                ],
                "exchanges": list(connected_exchanges.keys()),
                "timestamp": datetime.now().isoformat(),
                "source": "live"
            }
    except Exception as e:
        logger.warning(f"Could not fetch positions: {e}")
    
    # Fallback to mock
    return {
        "success": True,
        "positions": MOCK_POSITIONS,
        "exchanges": list(connected_exchanges.keys()),
        "timestamp": datetime.now().isoformat(),
        "source": "demo"
    }


# =============================================================================
# REPORTS API
# =============================================================================

@app.get("/api/reports")
async def get_reports(category: str = None, asset: str = None, limit: int = 20):
    """Get research reports - would be from database in production."""
    # For now return sample data - would be from MCF research database
    reports = [
        {
            "id": 1,
            "title": "BTC Accumulation Phase Confirmed: Smart Money Loading",
            "summary": "On-chain metrics show significant whale accumulation over past 72h. Exchange reserves at 3-year lows.",
            "category": "On-Chain Intel",
            "sentiment": "BULLISH",
            "sentimentColor": "green",
            "confidence": "HIGH",
            "timeAgo": "2 min ago",
            "author": "MCF Research",
            "assets": ["BTC"],
            "readTime": "5 min read",
            "created_at": datetime.now().isoformat()
        },
        # More reports would come from DB
    ]
    
    return {"success": True, "reports": reports[:limit]}


# =============================================================================
# 3D VISUALIZATION DATA API
# =============================================================================

@app.get("/api/viz-data/{viz_name}")
async def get_viz_data(viz_name: str, symbol: str = "BTC"):
    """Get formatted data for 3D visualizations."""
    import httpx
    import asyncio
    import random
    import math
    
    sym = symbol.upper()
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    
    if viz_name == "liquidation-topology":
        # Get liquidation data
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                res = await client.get(f"{base}/quant/liquidation-estimate/{sym}")
                data = res.json()
                
                current_price = data.get("current_price", 97000)
                
                # Build 3D surface data
                # X: Price levels, Y: Leverage, Z: Liquidation volume
                prices = []
                leverages = []
                volumes = []
                
                # Create grid
                price_range = list(range(int(current_price * 0.9), int(current_price * 1.1), int(current_price * 0.01)))
                lev_range = [5, 10, 25, 50, 75, 100, 125]
                
                for zone in data.get("downside_liquidation_zones", []):
                    price = zone.get("price", current_price * 0.95)
                    for lev in lev_range:
                        prices.append(price)
                        leverages.append(lev)
                        # More volume at typical leverage levels
                        base_vol = zone.get("estimated_usd_at_risk", 1e8) / 1e6
                        if lev in [10, 25, 50]:
                            volumes.append(base_vol * (1 + random.uniform(0, 0.5)))
                        else:
                            volumes.append(base_vol * random.uniform(0.2, 0.6))
                
                for zone in data.get("upside_liquidation_zones", []):
                    price = zone.get("price", current_price * 1.05)
                    for lev in lev_range:
                        prices.append(price)
                        leverages.append(lev)
                        base_vol = zone.get("estimated_usd_at_risk", 1e8) / 1e6
                        if lev in [10, 25, 50]:
                            volumes.append(base_vol * (1 + random.uniform(0, 0.5)))
                        else:
                            volumes.append(base_vol * random.uniform(0.2, 0.6))
                
                return {
                    "success": True,
                    "type": "scatter3d",
                    "data": {
                        "x": prices,
                        "y": leverages,
                        "z": volumes,
                        "mode": "markers",
                        "marker": {
                            "size": [max(4, v/20) for v in volumes],
                            "color": volumes,
                            "colorscale": "Hot",
                            "opacity": 0.8
                        }
                    },
                    "currentPrice": current_price,
                    "title": f"{sym} Liquidation Topology"
                }
        except Exception as e:
            logger.error(f"Liquidation topology error: {e}")
    
    elif viz_name == "funding-surface":
        # Funding rates across exchanges over time
        try:
            exchanges = ["Binance", "OKX", "Bybit", "Bitget", "dYdX", "Kraken"]
            hours = list(range(24))
            
            z_data = []
            for ex in exchanges:
                row = []
                base = random.uniform(-0.005, 0.01)
                for h in hours:
                    # Add some time-based variation
                    val = base + math.sin(h / 4) * 0.002 + random.uniform(-0.001, 0.001)
                    row.append(val * 100)  # Convert to percentage
                z_data.append(row)
            
            return {
                "success": True,
                "type": "surface",
                "data": {
                    "z": z_data,
                    "x": hours,
                    "y": exchanges,
                    "colorscale": [[0, "#ff3366"], [0.5, "#1a1a2e"], [1, "#00ff88"]],
                    "showscale": True
                },
                "title": f"{sym} Funding Rate Surface (24h)"
            }
        except Exception as e:
            logger.error(f"Funding surface error: {e}")
    
    elif viz_name == "oi-momentum":
        # OI changes over time with price correlation
        try:
            # Generate time series data
            times = list(range(48))  # 48 hours
            prices = []
            oi_values = []
            oi_deltas = []
            
            base_price = 97000
            base_oi = 9.5e9
            
            for t in times:
                # Simulate price movement
                price = base_price + math.sin(t / 8) * 1500 + random.uniform(-200, 200)
                prices.append(price)
                
                # OI tends to follow price with lag
                oi = base_oi + math.sin((t - 2) / 8) * 5e8 + random.uniform(-1e8, 1e8)
                oi_values.append(oi / 1e9)  # In billions
                
                # Delta
                if t > 0:
                    oi_deltas.append((oi_values[-1] - oi_values[-2]) * 100)
                else:
                    oi_deltas.append(0)
            
            return {
                "success": True,
                "type": "scatter3d",
                "data": {
                    "x": times,
                    "y": prices,
                    "z": oi_values,
                    "mode": "lines+markers",
                    "marker": {
                        "size": 4,
                        "color": oi_deltas,
                        "colorscale": "RdYlGn",
                        "showscale": True
                    },
                    "line": {"color": "#00ff88", "width": 2}
                },
                "title": f"{sym} OI vs Price (48h)"
            }
        except Exception as e:
            logger.error(f"OI momentum error: {e}")
    
    elif viz_name == "vol-surface":
        # Implied volatility surface (strike x expiry)
        try:
            # Strike prices as percentage from ATM
            strikes = [-20, -15, -10, -5, 0, 5, 10, 15, 20]  # % from ATM
            expiries = ["1D", "7D", "14D", "30D", "60D", "90D"]
            
            z_data = []
            for exp_idx, exp in enumerate(expiries):
                row = []
                # Base IV increases with expiry
                base_iv = 45 + exp_idx * 3
                for strike in strikes:
                    # Volatility smile - higher IV for OTM options
                    smile_adj = abs(strike) * 0.8
                    # Skew - puts typically have higher IV
                    skew_adj = -strike * 0.15 if strike < 0 else 0
                    iv = base_iv + smile_adj + skew_adj + random.uniform(-2, 2)
                    row.append(iv)
                z_data.append(row)
            
            return {
                "success": True,
                "type": "surface",
                "data": {
                    "z": z_data,
                    "x": strikes,
                    "y": list(range(len(expiries))),
                    "colorscale": "Viridis",
                    "showscale": True
                },
                "xLabels": [f"{s}%" for s in strikes],
                "yLabels": expiries,
                "title": f"{sym} IV Surface"
            }
        except Exception as e:
            logger.error(f"Vol surface error: {e}")
    
    elif viz_name == "monte-carlo":
        # Monte Carlo simulation paths
        try:
            starting = 100000
            paths = 50
            steps = 100
            win_rate = 0.73
            avg_win = 2.1
            avg_loss = 1.0
            position_size = 1.2
            
            all_paths = []
            for p in range(paths):
                path = [starting]
                capital = starting
                for s in range(steps):
                    if random.random() < win_rate:
                        capital *= (1 + (avg_win * position_size / 100))
                    else:
                        capital *= (1 - (avg_loss * position_size / 100))
                    path.append(capital)
                all_paths.append(path)
            
            # Calculate percentiles
            step_values = list(zip(*all_paths))
            p5 = [sorted(sv)[int(len(sv) * 0.05)] for sv in step_values]
            p25 = [sorted(sv)[int(len(sv) * 0.25)] for sv in step_values]
            p50 = [sorted(sv)[int(len(sv) * 0.50)] for sv in step_values]
            p75 = [sorted(sv)[int(len(sv) * 0.75)] for sv in step_values]
            p95 = [sorted(sv)[int(len(sv) * 0.95)] for sv in step_values]
            
            return {
                "success": True,
                "type": "multi-line",
                "data": {
                    "x": list(range(steps + 1)),
                    "paths": all_paths[:20],  # Show 20 sample paths
                    "percentiles": {
                        "p5": p5,
                        "p25": p25,
                        "p50": p50,
                        "p75": p75,
                        "p95": p95
                    }
                },
                "title": "Monte Carlo Equity Projection (100 trades)"
            }
        except Exception as e:
            logger.error(f"Monte carlo error: {e}")
    
    elif viz_name == "correlation-matrix":
        # Asset correlations as 3D bars
        try:
            assets = ["BTC", "ETH", "SOL", "AVAX", "LINK", "SPX", "DXY", "GOLD"]
            
            # Simulated correlation matrix
            corr_data = []
            for i, a1 in enumerate(assets):
                row = []
                for j, a2 in enumerate(assets):
                    if i == j:
                        corr = 1.0
                    elif (a1 in ["BTC", "ETH", "SOL", "AVAX", "LINK"] and 
                          a2 in ["BTC", "ETH", "SOL", "AVAX", "LINK"]):
                        corr = random.uniform(0.6, 0.95)
                    elif a2 == "DXY":
                        corr = random.uniform(-0.7, -0.3)
                    elif a2 == "SPX":
                        corr = random.uniform(0.4, 0.8)
                    else:
                        corr = random.uniform(-0.3, 0.5)
                    row.append(round(corr, 2))
                corr_data.append(row)
            
            return {
                "success": True,
                "type": "heatmap",
                "data": {
                    "z": corr_data,
                    "x": assets,
                    "y": assets,
                    "colorscale": [[0, "#ff3366"], [0.5, "#1a1a2e"], [1, "#00ff88"]],
                    "showscale": True
                },
                "title": "Asset Correlation Matrix"
            }
        except Exception as e:
            logger.error(f"Correlation matrix error: {e}")
    
    # Default fallback
    return {
        "success": False,
        "error": f"Unknown visualization: {viz_name}",
        "available": ["liquidation-topology", "funding-surface", "oi-momentum", "vol-surface", "monte-carlo", "correlation-matrix"]
    }


# =============================================================================
# POSITIONS API
# =============================================================================

@app.get("/api/positions")
async def get_positions():
    """Get all active positions with live prices."""
    import httpx
    import copy
    
    # Get live prices to update mock positions
    live_prices = {}
    try:
        async with httpx.AsyncClient(timeout=3.0) as client:
            # Fetch BTC price
            res = await client.get("https://api.kraken.com/0/public/Ticker?pair=XXBTZUSD")
            data = res.json()
            if data.get("result"):
                for key, ticker in data["result"].items():
                    live_prices["BTC"] = float(ticker["c"][0])
            
            # Fetch ETH price
            res = await client.get("https://api.kraken.com/0/public/Ticker?pair=XETHZUSD")
            data = res.json()
            if data.get("result"):
                for key, ticker in data["result"].items():
                    live_prices["ETH"] = float(ticker["c"][0])
            
            # Fetch SOL price
            res = await client.get("https://api.kraken.com/0/public/Ticker?pair=SOLUSD")
            data = res.json()
            if data.get("result"):
                for key, ticker in data["result"].items():
                    live_prices["SOL"] = float(ticker["c"][0])
    except Exception as e:
        logger.warning(f"Failed to fetch live prices for positions: {e}")
    
    # Update mock positions with live prices
    positions = copy.deepcopy(MOCK_POSITIONS)
    total_pnl_pct = 0
    
    for pos in positions:
        symbol = pos["symbol"].replace("-PERP", "")
        if symbol in live_prices:
            pos["current_price"] = live_prices[symbol]
            # Recalculate PnL
            entry = pos["entry_price"]
            current = pos["current_price"]
            if pos["direction"] == "long":
                pnl_pct = ((current - entry) / entry) * 100
            else:
                pnl_pct = ((entry - current) / entry) * 100
            pos["pnl_pct"] = round(pnl_pct, 2)
            total_pnl_pct += pos["pnl_pct"]
    
    return {
        "positions": positions,
        "summary": {
            "total_positions": len(positions),
            "total_pnl_pct": round(total_pnl_pct, 2),
            "total_exposure_usd": 70245,
            "risk_pct": 1.8
        }
    }


@app.get("/api/positions/{position_id}")
async def get_position(position_id: str):
    """Get a specific position."""
    for pos in MOCK_POSITIONS:
        if pos["id"] == position_id:
            return pos
    raise HTTPException(status_code=404, detail="Position not found")


# =============================================================================
# LIVE PRICE API (Multiple sources with fallback)
# =============================================================================

@app.get("/api/price/{symbol}")
async def get_live_price(symbol: str = "BTC"):
    """Get real-time price with multiple source fallback."""
    import httpx
    
    sym = symbol.upper()
    cache_key = f"price_{sym}"
    now = time.time()
    
    # Check cache
    if cache_key in price_cache:
        cached = price_cache[cache_key]
        if now - cached["time"] < cache_ttl:
            return cached["data"]
    
    result = None
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        # Try 1: Kraken (no geo-restrictions)
        try:
            kraken_symbol = "XXBTZUSD" if sym == "BTC" else f"X{sym}ZUSD" if sym == "ETH" else f"{sym}USD"
            url = f"https://api.kraken.com/0/public/Ticker?pair={kraken_symbol}"
            res = await client.get(url)
            data = res.json()
            
            if data.get("result"):
                for key, ticker in data["result"].items():
                    result = {
                        "symbol": sym,
                        "price": float(ticker["c"][0]),  # Last trade price
                        "change_24h": 0,  # Would need separate calc
                        "high_24h": float(ticker["h"][1]),
                        "low_24h": float(ticker["l"][1]),
                        "volume_24h": float(ticker["v"][1]),
                    }
                    break
        except Exception as e:
            logger.warning(f"Kraken price error: {e}")
        
        # Try 2: Coinbase if Kraken failed
        if not result:
            try:
                coinbase_symbol = f"{sym}-USD"
                url = f"https://api.exchange.coinbase.com/products/{coinbase_symbol}/ticker"
                res = await client.get(url)
                data = res.json()
                
                if data.get("price"):
                    result = {
                        "symbol": sym,
                        "price": float(data["price"]),
                        "change_24h": 0,
                        "high_24h": 0,
                        "low_24h": 0,
                        "volume_24h": float(data.get("volume", 0)),
                    }
            except Exception as e:
                logger.warning(f"Coinbase price error: {e}")
        
        # Try 3: CoinGecko as last resort
        if not result:
            try:
                coin_id = {"BTC": "bitcoin", "ETH": "ethereum", "SOL": "solana"}.get(sym, sym.lower())
                url = f"https://api.coingecko.com/api/v3/simple/price?ids={coin_id}&vs_currencies=usd&include_24hr_change=true"
                res = await client.get(url)
                data = res.json()
                
                if data.get(coin_id):
                    result = {
                        "symbol": sym,
                        "price": float(data[coin_id]["usd"]),
                        "change_24h": float(data[coin_id].get("usd_24h_change", 0)),
                        "high_24h": 0,
                        "low_24h": 0,
                        "volume_24h": 0,
                    }
            except Exception as e:
                logger.warning(f"CoinGecko price error: {e}")
    
    if result:
        price_cache[cache_key] = {"time": now, "data": result}
        return result
    
    # Return cached even if stale
    if cache_key in price_cache:
        return price_cache[cache_key]["data"]
    return {"symbol": sym, "price": 0, "error": "All price sources failed"}


@app.get("/api/klines/{symbol}")
async def get_klines(symbol: str = "BTC", interval: str = "15m", limit: int = 100):
    """Get OHLCV candles - tries multiple sources with fallback."""
    import httpx
    
    sym = symbol.upper()
    cache_key = f"klines_{sym}_{interval}"
    now = time.time()
    
    # Check cache (30 second TTL for Vercel - longer cache for serverless)
    if cache_key in price_cache:
        cached = price_cache[cache_key]
        if now - cached["time"] < 30:
            return cached["data"]
    
    candles = []
    
    # Shorter timeout for serverless
    async with httpx.AsyncClient(timeout=5.0) as client:
        # Try 1: Kraken (no geo-restrictions)
        try:
            kraken_symbol = f"X{sym}ZUSD" if sym == "BTC" else f"{sym}USD"
            if sym == "BTC":
                kraken_symbol = "XXBTZUSD"
            elif sym == "ETH":
                kraken_symbol = "XETHZUSD"
            else:
                kraken_symbol = f"{sym}USD"
            
            # Map intervals to Kraken (minutes)
            interval_mins = {"5m": 5, "15m": 15, "1h": 60, "4h": 240, "1d": 1440}
            kraken_interval = interval_mins.get(interval, 15)
            
            url = f"https://api.kraken.com/0/public/OHLC?pair={kraken_symbol}&interval={kraken_interval}"
            res = await client.get(url)
            data = res.json()
            
            if data.get("result"):
                # Get the first (only) result key that's not "last"
                for key, values in data["result"].items():
                    if key != "last" and isinstance(values, list):
                        for k in values[-limit:]:
                            candles.append({
                                "time": int(k[0]),
                                "open": float(k[1]),
                                "high": float(k[2]),
                                "low": float(k[3]),
                                "close": float(k[4]),
                                "volume": float(k[6]),
                            })
                        break
            
            if candles:
                logger.info(f"Klines from Kraken: {len(candles)} candles for {sym} {interval}")
        except Exception as e:
            logger.warning(f"Kraken klines error: {e}")
        
        # Try 2: Coinbase if Kraken failed
        if not candles:
            try:
                coinbase_symbol = f"{sym}-USD"
                # Map intervals to Coinbase granularity (seconds)
                granularity = {"5m": 300, "15m": 900, "1h": 3600, "4h": 14400, "1d": 86400}
                gran = granularity.get(interval, 900)
                
                url = f"https://api.exchange.coinbase.com/products/{coinbase_symbol}/candles?granularity={gran}"
                res = await client.get(url)
                data = res.json()
                
                if isinstance(data, list):
                    # Coinbase returns newest first, reverse it
                    for k in reversed(data[-limit:]):
                        candles.append({
                            "time": int(k[0]),
                            "open": float(k[3]),
                            "high": float(k[2]),
                            "low": float(k[1]),
                            "close": float(k[4]),
                            "volume": float(k[5]),
                        })
                
                if candles:
                    logger.info(f"Klines from Coinbase: {len(candles)} candles for {sym} {interval}")
            except Exception as e:
                logger.warning(f"Coinbase klines error: {e}")
    
    # Fallback: Generate synthetic candles if all sources failed
    if not candles:
        logger.warning(f"All kline sources failed for {sym}, using synthetic data")
        # Get current price for realistic synthetic data
        base_price = 97000 if sym == "BTC" else 3500 if sym == "ETH" else 150
        interval_seconds = {"5m": 300, "15m": 900, "1h": 3600, "4h": 14400, "1d": 86400}.get(interval, 900)
        
        import random
        current_time = int(now)
        price = base_price
        
        for i in range(limit):
            t = current_time - (limit - i) * interval_seconds
            change = random.uniform(-0.005, 0.005)  # 0.5% max change
            open_price = price
            close_price = price * (1 + change)
            high_price = max(open_price, close_price) * (1 + random.uniform(0, 0.002))
            low_price = min(open_price, close_price) * (1 - random.uniform(0, 0.002))
            
            candles.append({
                "time": t,
                "open": round(open_price, 2),
                "high": round(high_price, 2),
                "low": round(low_price, 2),
                "close": round(close_price, 2),
                "volume": random.uniform(100, 1000),
            })
            price = close_price
    
    result = {"symbol": sym, "interval": interval, "candles": candles, "source": "live" if len(candles) > 0 else "synthetic"}
    if candles:
        price_cache[cache_key] = {"time": now, "data": result}
    return result


# =============================================================================
# MARKET INTELLIGENCE API (Helsinki VM)
# =============================================================================

@app.get("/api/market/{symbol}")
async def get_market_data(symbol: str = "BTC"):
    """Get comprehensive market data from Helsinki VM."""
    init_clients()
    try:
        data = await helsinki.fetch_full_data(symbol.upper())
        formatted = helsinki.format_for_prompt(data)
        
        return {
            "symbol": symbol.upper(),
            "timestamp": data.timestamp,
            "price": data.meta.get("current_price"),
            "order_flow": data.order_flow,
            "derivatives": data.derivatives,
            "volatility": data.volatility,
            "sentiment": data.sentiment,
            "macro": data.macro,
            "formatted": formatted,
            "meta": data.meta
        }
    except Exception as e:
        logger.error(f"Helsinki fetch error: {e}")
        raise HTTPException(status_code=502, detail=f"Helsinki VM error: {str(e)}")


@app.get("/api/cvd/{symbol}")
async def get_cvd(symbol: str = "BTC"):
    """Get CVD data for a symbol."""
    init_clients()
    import httpx
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            res = await client.get(f"{base}/quant/cvd/{symbol.upper()}")
            data = res.json()
            logger.info(f"CVD raw for {symbol}: {data}")
            
            # Parse CVD data according to Helsinki format
            cvd = {
                "cvd_1h": data.get("cvd_1h", 0),
                "cvd_4h": data.get("cvd_4h", 0),
                "cvd_1d": data.get("cvd_total", data.get("cvd_24h", 0)),
                "cvd_1h_usd": data.get("cvd_1h_usd", 0),
                "divergence": data.get("divergence", "NONE"),
                "signal": data.get("signal", "NEUTRAL"),
                "interpretation": data.get("interpretation", ""),
            }
            
            return {"symbol": symbol.upper(), "cvd": cvd, "raw": data}
    except Exception as e:
        logger.error(f"CVD fetch error: {e}")
        return {"symbol": symbol.upper(), "cvd": {"cvd_1h": 0, "cvd_4h": 0, "cvd_1d": 0}, "error": str(e)}


@app.get("/api/volatility/{symbol}")
async def get_volatility(symbol: str = "BTC"):
    """Get volatility data for a symbol."""
    init_clients()
    try:
        data = await helsinki.fetch_volatility_data(symbol.upper())
        return data
    except Exception as e:
        raise HTTPException(status_code=502, detail=str(e))


@app.get("/api/liquidations/{symbol}")
async def get_liquidations(symbol: str = "BTC"):
    """Get liquidation data for a symbol."""
    init_clients()
    try:
        data = await helsinki.fetch_liquidation_data(symbol.upper())
        return data
    except Exception as e:
        raise HTTPException(status_code=502, detail=str(e))


@app.get("/api/funding")
async def get_funding():
    """Get funding rates for all major pairs."""
    init_clients()
    import httpx
    import asyncio
    
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    rates = {"BTC": 0, "ETH": 0, "SOL": 0}
    basis = 0
    
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            # Fetch liquidation-estimate for each symbol (contains funding_rate_pct)
            async def get_funding_for(symbol):
                try:
                    res = await client.get(f"{base}/quant/liquidation-estimate/{symbol}")
                    data = res.json()
                    return symbol, data.get("funding_rate_pct", 0) / 100  # Convert from % to decimal
                except:
                    return symbol, 0
            
            results = await asyncio.gather(
                get_funding_for("BTC"),
                get_funding_for("ETH"),
                get_funding_for("SOL")
            )
            
            for symbol, rate in results:
                rates[symbol] = rate
            
            # Get basis from BTC
            try:
                basis_res = await client.get(f"{base}/quant/basis/BTC")
                basis_data = basis_res.json()
                basis = basis_data.get("basis_percent", basis_data.get("basis", 0))
            except:
                pass
            
            logger.info(f"Funding rates: {rates}, Basis: {basis}")
            
            return {
                "rates": rates, 
                "basis": basis,
                "next_funding": "~4h", 
                "source": "Helsinki"
            }
    except Exception as e:
        logger.error(f"Funding fetch error: {e}")
        return {"rates": {"BTC": 0.0001, "ETH": 0.00008, "SOL": 0.0002}, "basis": 0.12, "next_funding": "~4h", "source": "fallback"}


@app.get("/api/oi/{symbol}")
async def get_open_interest(symbol: str = "BTC"):
    """Get open interest data."""
    init_clients()
    import httpx
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            res = await client.get(f"{base}/quant/open-interest/{symbol.upper()}")
            data = res.json()
            logger.info(f"OI raw for {symbol}: {data}")
            
            # Parse OI data
            oi = {
                "total_oi": data.get("oi_value", data.get("open_interest", data.get("value", 0))),
                "change_24h": data.get("oi_change_24h", data.get("change_24h", data.get("oi_change", 0))),
                "trend": data.get("trend", "stable"),
                "interpretation": data.get("interpretation", ""),
            }
            
            return {"symbol": symbol.upper(), "oi": oi, "raw": data}
    except Exception as e:
        logger.error(f"OI fetch error: {e}")
        return {"symbol": symbol.upper(), "oi": {"total_oi": 0, "change_24h": 0}}


@app.get("/api/fear-greed")
async def get_fear_greed():
    """Get fear and greed index from multiple sources."""
    init_clients()
    import httpx
    
    # Try Coinglass first (premium)
    try:
        result = await coinglass.get_fear_greed_index()
        if result.success and result.data:
            data = result.data
            value = data.get("value") or data.get("index") or 50
            return {
                "value": int(value),
                "label": "EXTREME FEAR" if value <= 20 else "FEAR" if value <= 40 else "NEUTRAL" if value <= 60 else "GREED" if value <= 80 else "EXTREME GREED"
            }
    except Exception as e:
        logger.error(f"Coinglass F&G error: {e}")
    
    # Fallback to alternative.me API (free)
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            alt_res = await client.get("https://api.alternative.me/fng/?limit=1")
            alt_data = alt_res.json()
            if alt_data.get("data"):
                value = int(alt_data["data"][0]["value"])
                return {
                    "value": value,
                    "label": alt_data["data"][0]["value_classification"].upper()
                }
    except Exception as e:
        logger.error(f"Alternative.me F&G fetch error: {e}")
    
    return {"value": 50, "label": "NEUTRAL"}


# =============================================================================
# SESSION STATS API
# =============================================================================

@app.get("/api/session/stats")
async def get_session_stats():
    """Get current session statistics."""
    return {
        "session_pnl": 4247.32,
        "session_pnl_pct": 2.8,
        "active_positions": len(MOCK_POSITIONS),
        "win_rate": 73,
        "avg_r": 1.8,
        "max_drawdown": -0.4,
        "trades_today": 7,
        "wins": 5,
        "losses": 2
    }


# =============================================================================
# ALERTS API
# =============================================================================

MOCK_ALERTS = [
    {
        "id": "alert_001",
        "type": "target_hit",
        "level": "success",
        "title": "TARGET 1 HIT",
        "message": "BTC-PERP reached $96,800 (+1.2R). Stop moved to breakeven.",
        "timestamp": "14:31:42"
    },
    {
        "id": "alert_002",
        "type": "momentum_tp",
        "level": "info",
        "title": "MOMENTUM TP",
        "message": "Slope strength: 2.3x. Trailing 0.45% below candle body.",
        "timestamp": "14:28:17"
    },
    {
        "id": "alert_003",
        "type": "volatility",
        "level": "warning",
        "title": "VOLATILITY",
        "message": "Regime: NORMAL  HIGH. Recommended: Reduce new entries 25%.",
        "timestamp": "14:25:33"
    },
    {
        "id": "alert_004",
        "type": "shot_executed",
        "level": "success",
        "title": "SHOT 2 EXECUTED",
        "message": "BTC-PERP: Added 0.15 BTC @ $95,890.",
        "timestamp": "14:22:08"
    }
]


@app.get("/api/alerts")
async def get_alerts(limit: int = 10):
    """Get recent alerts."""
    return {"alerts": MOCK_ALERTS[:limit]}


# =============================================================================
# NEURAL ASSISTANT API
# =============================================================================

def _format_market_data_for_iros(symbol: str, market_data: dict) -> str:
    """Format market data into a clean context string for IROS."""
    lines = []
    
    lines.append("## VERIFIED LIVE DATA - DO NOT HALLUCINATE")
    lines.append(f"## USE ONLY THESE {symbol} NUMBERS\n")
    
    # Current market overview
    price_found = False
    if market_data.get("coins_markets"):
        for coin in market_data["coins_markets"]:
            if coin.get("symbol", "").upper() == symbol.upper():
                price = coin.get('price', 0)
                if price > 0:
                    price_found = True
                    lines.append(f"""
**{symbol} CURRENT PRICE: ${price:,.2f}**
- 24h Change: {coin.get('priceChangePercent24h', 0):.2f}%
- Open Interest: ${coin.get('openInterest', 0)/1e9:.2f}B
- Funding Rate: {coin.get('fundingRate', 0)*100:.4f}%
- Long/Short: {coin.get('longRate', 50):.1f}% / {coin.get('shortRate', 50):.1f}%
""")
                break
    
    if not price_found:
        lines.append(f"**WARNING: Price data missing for {symbol}**")
    
    # Whale positions - CORRECT FIELD NAMES
    if market_data.get("whale_positions"):
        all_pos = market_data["whale_positions"]
        sym_pos = [p for p in all_pos if p.get("symbol", "").upper() == symbol.upper()]
        if sym_pos:
            total_long = sum(abs(p.get("positionValueUsd", 0)) for p in sym_pos if p.get("positionSize", 0) > 0)
            total_short = sum(abs(p.get("positionValueUsd", 0)) for p in sym_pos if p.get("positionSize", 0) < 0)
            lines.append(f"\n**WHALES ({len(sym_pos)}):** Long ${total_long/1e6:.1f}M | Short ${total_short/1e6:.1f}M")
            sorted_pos = sorted(sym_pos, key=lambda x: abs(x.get("positionValueUsd", 0)), reverse=True)
            for i, w in enumerate(sorted_pos[:5]):
                side = "LONG" if w.get("positionSize", 0) > 0 else "SHORT"
                val = abs(w.get("positionValueUsd", 0)) / 1e6
                lines.append(f"  {i+1}. {side} ${val:.1f}M @ ${w.get('entryPrice', 0):,.0f}")
    
    # Funding - handle nested structure
    if market_data.get("funding"):
        fd = market_data["funding"]
        rates = []
        if isinstance(fd, dict):
            for ml in ["usdtOrUsdMarginList", "tokenMarginList"]:
                for item in fd.get(ml, []):
                    r = item.get("rate", 0) or item.get("fundingRate", 0)
                    if r: rates.append(f"{item.get('exchangeName', '?')}: {r*100:.4f}%")
        if rates:
            lines.append("\n**FUNDING:** " + " | ".join(rates[:3]))
    
    return "\n".join(lines) if lines else "No data"


@app.post("/api/neural/chat")
async def neural_chat(request: Dict[str, Any]):
    """Chat with the Bastion AI - includes user position context."""
    init_clients()  # Ensure clients are ready
    
    query = request.get("query", "")
    symbol = request.get("symbol", "BTC")
    include_positions = request.get("include_positions", True)
    
    if not query:
        raise HTTPException(status_code=400, detail="Query is required")
    
    # Extract context from query
    context = query_processor.extract_context(query)
    
    # Get user positions for AI context
    position_context = ""
    user_positions = []
    if include_positions:
        try:
            positions = await user_context.get_all_positions()
            if positions:
                position_context = user_context.get_position_context_for_ai(positions)
                user_positions = [
                    {
                        "symbol": p.symbol,
                        "direction": p.direction,
                        "entry": p.entry_price,
                        "current": p.current_price,
                        "pnl": p.pnl,
                        "pnl_pct": p.pnl_pct
                    }
                    for p in positions
                ]
        except Exception as e:
            logger.warning(f"Could not fetch user positions: {e}")
            # Fall back to mock positions if no exchange connected
            position_context = """User's Current Positions (Demo):
- BTC-PERP LONG: Entry $95,120, Current $96,847, P&L +$776 (+1.82%)
- ETH-PERP SHORT: Entry $3,245, Current $3,198, P&L +$244 (+1.47%)
- SOL-PERP LONG: Entry $142.80, Current $141.20, P&L -$80 (-1.12%)"""
    
    # Fetch live market data for IROS
    import asyncio
    
    market_data = {}
    data_sources = []
    
    try:
        if coinglass is None:
            logger.warning("Coinglass client not initialized")
            raise ValueError("Coinglass not available")
            
        # Fetch Coinglass data in parallel
        cg_results = await asyncio.gather(
            coinglass.get_coins_markets(),
            coinglass.get_hyperliquid_whale_positions(symbol),
            coinglass.get_funding_rates(symbol),
            coinglass.get_long_short_ratio(symbol),
            coinglass.get_options_max_pain(symbol),
            return_exceptions=True
        )
        
        # Parse results
        if hasattr(cg_results[0], 'data') and cg_results[0].data:
            market_data["coins_markets"] = cg_results[0].data
            data_sources.append("Coinglass:markets")
        
        if hasattr(cg_results[1], 'data') and cg_results[1].data:
            market_data["whale_positions"] = cg_results[1].data
            data_sources.append("Hyperliquid:whales")
        
        if hasattr(cg_results[2], 'data') and cg_results[2].data:
            market_data["funding"] = cg_results[2].data
            data_sources.append("Coinglass:funding")
        
        if hasattr(cg_results[3], 'data') and cg_results[3].data:
            market_data["ls_ratio"] = cg_results[3].data
            data_sources.append("Coinglass:ls-ratio")
        
        if hasattr(cg_results[4], 'data') and cg_results[4].data:
            market_data["max_pain"] = cg_results[4].data
            data_sources.append("Coinglass:options")
            
    except Exception as e:
        logger.error(f"Failed to fetch market data: {e}")
    
    # Format market data for IROS prompt
    market_context = _format_market_data_for_iros(symbol, market_data)
    
    # Build full context for IROS (truncate to avoid exceeding 8K token limit)
    # Rough estimate: 4 chars = 1 token, so max ~20K chars for safety
    truncated_context = market_context[:15000] if len(market_context) > 15000 else market_context
    
    full_context = f"""
USER QUERY: {query}
SYMBOL: {symbol}

{position_context[:2000] if position_context else ''}

LIVE MARKET DATA:
{truncated_context}
"""
    
    # Call IROS model
    model_url = os.getenv("BASTION_MODEL_URL")
    
    if model_url:
        try:
            import httpx
            
            # Keep prompt minimal - model has 8K context limit
            # Extract just key metrics for the prompt
            price_line = ""
            if market_data.get("coins_markets"):
                # Search ALL coins, not just first 3
                for coin in market_data["coins_markets"]:
                    coin_symbol = coin.get("symbol", "").upper().replace("USDT", "").replace("USD", "")
                    if coin_symbol == symbol.upper():
                        price = float(coin.get('price', 0) or 0)
                        change = float(coin.get('priceChangePercent24h', 0) or 0)
                        oi = float(coin.get('openInterest', 0) or 0)
                        funding = float(coin.get('fundingRate', 0) or 0)
                        price_line = f"CURRENT PRICE: ${price:,.2f}, 24h Change: {change:+.1f}%, Open Interest: ${oi/1e9:.2f}B, Funding: {funding*100:.4f}%"
                        logger.info(f"Found {symbol} price: ${price:,.2f}")
                        break
            
            if not price_line:
                logger.warning(f"Price not found for {symbol} in coins_markets")
            
            # Build data summary from Coinglass
            whale_summary = ""
            if market_data.get("whale_positions"):
                longs = sum(float(p.get("positionValueUsd", 0) or 0) for p in market_data["whale_positions"] if float(p.get("positionSize", 0) or 0) > 0)
                shorts = sum(abs(float(p.get("positionValueUsd", 0) or 0)) for p in market_data["whale_positions"] if float(p.get("positionSize", 0) or 0) < 0)
                whale_summary = f"Whale Longs: ${longs/1e6:.1f}M, Whale Shorts: ${shorts/1e6:.1f}M"
            
            funding_summary = ""
            if market_data.get("funding"):
                for f in market_data["funding"][:5]:
                    if f.get("exchangeName") == "Binance":
                        funding_summary = f"Binance Funding: {float(f.get('rate', 0))*100:.4f}%"
                        break
            
            system_prompt = f"""You are BASTION, an institutional crypto trading analyst.

CRITICAL: Your training data is OUTDATED. USE ONLY the data provided below. DO NOT make up prices or statistics.

## VERIFIED {symbol} DATA (LIVE FROM COINGLASS)
{price_line}
{whale_summary}
{funding_summary}

RULES:
1. ONLY use the exact numbers provided above
2. DO NOT invent prices, whale positions, or market data
3. If data is missing, say "data unavailable" - do NOT guess
4. Be concise but accurate

USER QUERY: {query}"""
            
            logger.info(f"IROS prompt: {len(system_prompt)} chars")
            
            model_api_key = os.getenv("BASTION_MODEL_API_KEY", "5c37b5e8e6c2480813aa0cfd4de5c903544b7a000bff729e1c99d9b4538eb34d")
            
            async with httpx.AsyncClient(timeout=120.0) as client:  # 2 min timeout for slower responses
                response = await client.post(
                    f"{model_url}/v1/chat/completions",
                    json={
                        "model": "iros",
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": query}
                        ],
                        "max_tokens": 800,
                        "temperature": 0.7
                    },
                    headers={
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {model_api_key}"
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    logger.info(f"IROS raw response keys: {result.keys()}")
                    
                    choices = result.get("choices", [])
                    if choices and len(choices) > 0:
                        message = choices[0].get("message", {})
                        ai_response = message.get("content", "")
                        
                        logger.info(f"IROS content length: {len(ai_response) if ai_response else 0}")
                        
                        if ai_response:
                            data_sources.append("IROS:32B-LLM")
                            return {
                                "success": True,
                                "response": ai_response,
                                "context": {
                                    "symbol": context.symbol,
                                    "capital": context.capital,
                                    "timeframe": context.timeframe,
                                    "intent": context.query_intent,
                                    "has_positions": len(user_positions) > 0,
                                    "position_count": len(user_positions)
                                },
                                "user_positions": user_positions,
                                "data_sources": data_sources
                            }
                        else:
                            iros_error = f"Empty content in response. Message: {message}"
                    else:
                        iros_error = f"No choices in response. Result: {str(result)[:200]}"
                else:
                    logger.error(f"IROS model error: {response.status_code} - {response.text[:500]}")
                    iros_error = f"HTTP {response.status_code}: {response.text[:200]}"
                    
        except Exception as e:
            logger.error(f"IROS call failed: {e}")
            # Include error in fallback for debugging
            iros_error = str(e)
    
    # Fallback if IROS unavailable
    error_info = f"\nDebug: {iros_error}" if 'iros_error' in dir() else ""
    response = f"""**Analysis for {symbol}**

 IROS model not available. Using rule-based fallback.

Market Data Summary:
{market_context if market_context else 'Unable to fetch live data.'}

**Recommendation:** Check BASTION_MODEL_URL configuration.{error_info}"""
    
    return {
        "success": True,
        "response": response,
        "context": {
            "symbol": context.symbol,
            "capital": context.capital,
            "timeframe": context.timeframe,
            "intent": context.query_intent,
            "has_positions": len(user_positions) > 0,
            "position_count": len(user_positions)
        },
        "user_positions": user_positions,
        "data_sources": data_sources,
        "fallback": True
    }


# =============================================================================
# ACTIONS API
# =============================================================================

@app.post("/api/actions/emergency-exit")
async def emergency_exit():
    """Emergency exit all positions."""
    logger.warning(" EMERGENCY EXIT triggered!")
    # In production, this would call exchange APIs
    return {
        "success": True,
        "message": "Emergency exit initiated for all positions",
        "positions_closed": len(MOCK_POSITIONS)
    }


@app.post("/api/actions/move-to-breakeven")
async def move_to_breakeven(request: Dict[str, Any]):
    """Move stops to breakeven."""
    position_id = request.get("position_id")
    
    if position_id:
        return {"success": True, "message": f"Position {position_id} stop moved to breakeven"}
    
    return {"success": True, "message": "All profitable positions moved to breakeven"}


@app.post("/api/actions/add-shot")
async def add_shot(request: Dict[str, Any]):
    """Add a shot to an existing position."""
    position_id = request.get("position_id")
    size = request.get("size", 0.1)
    
    return {
        "success": True,
        "message": f"Shot added to {position_id}",
        "new_size": size
    }


@app.post("/api/actions/partial-close")
async def partial_close(request: Dict[str, Any]):
    """Close a percentage of a position."""
    position_id = request.get("position_id")
    percentage = request.get("percentage", 50)
    
    return {
        "success": True,
        "message": f"Closed {percentage}% of {position_id}"
    }


# =============================================================================
# MCF LABS REPORTS API
# =============================================================================

# Global MCF Labs instances
_mcf_generator = None
_mcf_storage = None


def _init_mcf():
    """Initialize MCF Labs components on first use"""
    global _mcf_generator, _mcf_storage
    
    if _mcf_storage is None:
        try:
            # Use hybrid storage (Supabase + filesystem)
            from mcf_labs.storage import get_hybrid_storage
            _mcf_storage = get_hybrid_storage()
            
            if _mcf_storage.supabase_available:
                logger.info("[MCF] Report storage initialized with Supabase")
            else:
                logger.info("[MCF] Report storage initialized (filesystem only)")
        except Exception as e:
            logger.warning(f"[MCF] Storage init failed: {e}")
    
    if _mcf_generator is None and coinglass is not None:
        try:
            import os
            model_url = os.getenv("BASTION_MODEL_URL")
            
            if model_url:
                from mcf_labs.iros_generator import create_iros_generator
                _mcf_generator = create_iros_generator(
                    coinglass_client=coinglass,
                    helsinki_client=helsinki,
                    whale_alert_client=whale_alert,
                    model_url=model_url,
                    model_api_key=os.getenv("BASTION_MODEL_API_KEY")
                )
                logger.info("[MCF] IROS generator initialized")
            else:
                from mcf_labs.generator import ReportGenerator
                _mcf_generator = ReportGenerator(
                    coinglass_client=coinglass,
                    helsinki_client=helsinki,
                    whale_alert_client=whale_alert
                )
                logger.info("[MCF] Rule-based generator initialized")
        except Exception as e:
            logger.warning(f"[MCF] Generator init failed: {e}")


@app.get("/api/mcf/reports")
async def get_mcf_reports(
    type: Optional[str] = None,
    symbol: Optional[str] = None,
    bias: Optional[str] = None,
    limit: int = 20,
    offset: int = 0
):
    """
    Get MCF Labs reports for Research Terminal.
    
    Query params:
        type: Filter by report type (market_structure, whale_intelligence, etc.)
        symbol: Filter by symbol tag (btc, eth, sol)
        bias: Filter by bias (BULLISH, BEARISH, NEUTRAL)
        limit: Number of reports to return (default 20)
        offset: Pagination offset
    """
    _init_mcf()
    
    if _mcf_storage is None:
        return {"success": False, "error": "Report storage not initialized", "reports": []}
    
    try:
        from mcf_labs.models import ReportType
        
        # Convert type string to enum if provided
        report_type = None
        if type:
            try:
                report_type = ReportType(type)
            except ValueError:
                pass
        
        reports = _mcf_storage.list_reports(
            report_type=report_type,
            limit=limit + offset,
            bias=bias
        )
        
        # Filter by symbol if provided
        if symbol:
            symbol_lower = symbol.lower()
            reports = [r for r in reports if symbol_lower in r.tags]
        
        # Apply offset
        reports = reports[offset:offset + limit]
        
        return {
            "success": True,
            "reports": [r.to_dict() for r in reports],
            "count": len(reports)
        }
        
    except Exception as e:
        logger.error(f"[MCF] Get reports error: {e}")
        return {"success": False, "error": str(e), "reports": []}


@app.get("/api/mcf/reports/latest")
async def get_latest_mcf_reports():
    """Get the most recent report of each type"""
    _init_mcf()
    
    if _mcf_storage is None:
        return {"success": False, "error": "Report storage not initialized"}
    
    try:
        latest = _mcf_storage.get_latest_by_type()
        
        return {
            "success": True,
            "reports": {
                k: v.to_dict() if v else None 
                for k, v in latest.items()
            }
        }
        
    except Exception as e:
        logger.error(f"[MCF] Get latest reports error: {e}")
        return {"success": False, "error": str(e)}


@app.get("/api/mcf/reports/{report_id}")
async def get_mcf_report_detail(report_id: str):
    """Get a specific report by ID"""
    _init_mcf()
    
    if _mcf_storage is None:
        return {"success": False, "error": "Report storage not initialized"}
    
    try:
        report = _mcf_storage.get_report(report_id)
        
        if report:
            return {"success": True, "report": report.to_dict()}
        return {"success": False, "error": "Report not found"}
        
    except Exception as e:
        logger.error(f"[MCF] Get report error: {e}")
        return {"success": False, "error": str(e)}


@app.post("/api/mcf/generate/{report_type}")
async def generate_mcf_report(
    report_type: str,
    symbol: str = "BTC"
):
    """
    Manually trigger report generation.
    
    Args:
        report_type: Type of report (market_structure, whale, options, cycle)
        symbol: Symbol to generate for (default BTC)
    """
    _init_mcf()
    
    if _mcf_generator is None:
        return {"success": False, "error": "Report generator not initialized"}
    
    try:
        report = None
        
        if report_type == "market_structure":
            report = await _mcf_generator.generate_market_structure(symbol)
        elif report_type in ["whale", "whale_intelligence"]:
            report = await _mcf_generator.generate_whale_report(symbol)
        elif report_type in ["options", "options_flow"]:
            report = await _mcf_generator.generate_options_report(symbol)
        elif report_type in ["cycle", "cycle_position"]:
            report = await _mcf_generator.generate_cycle_report(symbol)
        else:
            return {"success": False, "error": f"Unknown report type: {report_type}"}
        
        if report:
            # Save report if storage is available
            if _mcf_storage:
                try:
                    from mcf_labs.scheduler import ReportScheduler
                    scheduler = ReportScheduler(_mcf_generator)
                    await scheduler.save_report(report)
                except Exception as e:
                    logger.warning(f"[MCF] Could not save report: {e}")
            
            return {
                "success": True,
                "report": report.to_dict(),
                "message": f"Generated {report_type} report for {symbol}"
            }
        
        return {"success": False, "error": "Report generation failed"}
        
    except Exception as e:
        logger.error(f"[MCF] Generate report error: {e}")
        return {"success": False, "error": str(e)}


@app.get("/api/mcf/status")
async def get_mcf_status():
    """Get MCF Labs system status"""
    _init_mcf()
    
    import os
    from mcf_labs.scheduler import get_scheduler, _running
    
    scheduler = get_scheduler()
    
    # Check Supabase status
    supabase_status = False
    if _mcf_storage and hasattr(_mcf_storage, 'supabase_available'):
        supabase_status = _mcf_storage.supabase_available
    
    # Count reports
    report_count = 0
    if _mcf_storage:
        try:
            report_count = _mcf_storage.count_reports()
        except:
            pass
    
    return {
        "success": True,
        "status": {
            "storage_initialized": _mcf_storage is not None,
            "supabase_connected": supabase_status,
            "report_count": report_count,
            "generator_initialized": _mcf_generator is not None,
            "scheduler_running": _running,
            "scheduler_initialized": scheduler is not None,
            "iros_enabled": os.getenv("BASTION_MODEL_URL") is not None,
            "coinglass_available": coinglass is not None,
            "helsinki_available": helsinki is not None
        }
    }


@app.post("/api/mcf/sync-supabase")
async def sync_reports_to_supabase():
    """Sync all filesystem reports to Supabase"""
    _init_mcf()
    
    if _mcf_storage is None:
        return {"success": False, "error": "Storage not initialized"}
    
    if not hasattr(_mcf_storage, 'sync_to_supabase'):
        return {"success": False, "error": "Hybrid storage not available"}
    
    if not _mcf_storage.supabase_available:
        return {"success": False, "error": "Supabase not connected - check SUPABASE_URL and SUPABASE_KEY"}
    
    try:
        synced = _mcf_storage.sync_to_supabase()
        return {"success": True, "synced_count": synced, "message": f"Synced {synced} reports to Supabase"}
    except Exception as e:
        logger.error(f"[MCF] Sync error: {e}")
        return {"success": False, "error": str(e)}


@app.post("/api/mcf/generate-all")
async def generate_all_mcf_reports(background_tasks: "BackgroundTasks" = None):
    """Trigger generation of all report types for all supported coins"""
    from fastapi import BackgroundTasks
    from mcf_labs.scheduler import get_scheduler, SUPPORTED_COINS
    
    _init_mcf()
    scheduler = get_scheduler()
    
    if scheduler is None and _mcf_generator is not None:
        # Create a temporary scheduler if none running
        from mcf_labs.scheduler import ReportScheduler
        scheduler = ReportScheduler(_mcf_generator)
    
    if scheduler is None:
        return {"success": False, "error": "No scheduler or generator available"}
    
    # Run generation in background
    async def generate_batch():
        results = {"market_structure": [], "whale_intelligence": [], "cycle": []}
        
        # Generate market structure for all coins
        for symbol in SUPPORTED_COINS:
            try:
                report = await scheduler.run_market_structure(symbol)
                if report:
                    results["market_structure"].append(symbol)
            except Exception as e:
                logger.error(f"Failed market structure for {symbol}: {e}")
        
        # Generate whale reports for all coins  
        for symbol in SUPPORTED_COINS:
            try:
                report = await scheduler.run_whale_report(symbol)
                if report:
                    results["whale_intelligence"].append(symbol)
            except Exception as e:
                logger.error(f"Failed whale report for {symbol}: {e}")
        
        # Generate cycle report for BTC
        try:
            report = await scheduler.run_cycle_report("BTC")
            if report:
                results["cycle"].append("BTC")
        except Exception as e:
            logger.error(f"Failed cycle report: {e}")
        
        logger.info(f"[MCF] Batch generation complete: {results}")
        return results
    
    # Start generation
    asyncio.create_task(generate_batch())
    
    return {
        "success": True,
        "message": "Batch report generation started in background",
        "coins": SUPPORTED_COINS
    }


# =============================================================================
# WEBSOCKET FOR REAL-TIME UPDATES
# =============================================================================

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket for real-time terminal updates."""
    await websocket.accept()
    active_connections.append(websocket)
    logger.info(f"WebSocket connected. Total: {len(active_connections)}")
    
    try:
        # Send initial data
        await websocket.send_json({
            "type": "connected",
            "message": "BASTION Terminal connected",
            "timestamp": datetime.now().isoformat()
        })
        
        # Start sending updates
        while True:
            # Fetch real prices from cache or API
            import httpx
            prices = {}
            try:
                async with httpx.AsyncClient(timeout=2.0) as client:
                    res = await client.get("https://api.kraken.com/0/public/Ticker?pair=XXBTZUSD,XETHZUSD,SOLUSD")
                    data = res.json()
                    if data.get("result"):
                        for key, ticker in data["result"].items():
                            price = float(ticker["c"][0])
                            if "XBT" in key:
                                prices["BTC-PERP"] = price
                            elif "ETH" in key:
                                prices["ETH-PERP"] = price
                            elif "SOL" in key:
                                prices["SOL-PERP"] = price
            except:
                pass
            
            # Only send if we got prices
            if prices:
                price_update = {
                    "type": "price_update",
                    "data": prices,
                    "timestamp": datetime.now().isoformat()
                }
                await websocket.send_json(price_update)
            
            # Check for incoming messages
            try:
                data = await asyncio.wait_for(websocket.receive_text(), timeout=1.0)
                message = json.loads(data)
                logger.info(f"Received: {message}")
            except asyncio.TimeoutError:
                pass
            
            await asyncio.sleep(1)
            
    except WebSocketDisconnect:
        active_connections.remove(websocket)
        logger.info(f"WebSocket disconnected. Total: {len(active_connections)}")


# =============================================================================
# HEALTH CHECK
# =============================================================================

# =============================================================================
# WHALE ALERT API
# =============================================================================

@app.get("/api/whales")
async def get_whale_transactions(min_value: int = 1000000, limit: int = 20):
    """Get recent whale transactions."""
    init_clients()
    try:
        result = await whale_alert.get_transactions(min_value=min_value, limit=limit)
        
        if not result.success:
            return {"success": False, "error": result.error, "transactions": []}
        
        # Format transactions for frontend
        transactions = []
        for tx in result.transactions:
            # Determine if deposit or withdrawal
            direction = "TRANSFER"
            if tx.from_owner_type == "exchange" and tx.to_owner_type != "exchange":
                direction = "WITHDRAWAL"
            elif tx.from_owner_type != "exchange" and tx.to_owner_type == "exchange":
                direction = "DEPOSIT"
            elif tx.transaction_type == "mint":
                direction = "MINT"
            elif tx.transaction_type == "burn":
                direction = "BURN"
            
            transactions.append({
                "id": tx.id,
                "symbol": tx.symbol.upper(),
                "amount": tx.amount,
                "amount_usd": tx.amount_usd,
                "from": tx.from_owner or tx.from_address[:12] + "...",
                "to": tx.to_owner or tx.to_address[:12] + "...",
                "direction": direction,
                "timestamp": tx.timestamp.strftime("%H:%M:%S"),
                "blockchain": tx.blockchain,
            })
        
        return {"success": True, "transactions": transactions}
    except Exception as e:
        logger.error(f"Whale fetch error: {e}")
        return {"success": False, "error": str(e), "transactions": []}


@app.get("/api/whales/flows/{symbol}")
async def get_whale_flows(symbol: str = "BTC", hours: int = 24):
    """Get exchange inflows/outflows for a symbol."""
    try:
        flows = await whale_alert.get_exchange_flows(symbol=symbol.lower(), hours=hours)
        return {"success": True, "flows": flows}
    except Exception as e:
        logger.error(f"Whale flows error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# COINGLASS API (Premium)
# =============================================================================

@app.get("/api/heatmap/{symbol}")
async def get_liquidation_heatmap(symbol: str = "BTC", t: int = 0):
    """Get liquidation heatmap - try Helsinki first (free, unlimited)."""
    init_clients()
    import httpx
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    
    # Always fetch fresh - no caching for heatmap
    try:
        async with httpx.AsyncClient(timeout=8.0) as client:
            res = await client.get(f"{base}/quant/liquidation-estimate/{symbol.upper()}?nocache={t}")
            data = res.json()
            logger.info(f"Heatmap raw for {symbol}: {data}")
            
            if data and "current_price" in data:
                # Convert Helsinki format to heatmap format
                levels = []
                current_price = data.get("current_price", 0)
                
                # Add downside liquidation zones (longs at risk)
                for zone in data.get("downside_liquidation_zones", []):
                    levels.append({
                        "price": zone.get("price", 0),
                        "longLiquidation": zone.get("estimated_usd_at_risk", 0),
                        "shortLiquidation": 0,
                        "leverage": zone.get("leverage_concentration", "unknown")
                    })
                
                # Add upside liquidation zones (shorts at risk)
                for zone in data.get("upside_liquidation_zones", []):
                    levels.append({
                        "price": zone.get("price", 0),
                        "longLiquidation": 0,
                        "shortLiquidation": zone.get("estimated_usd_at_risk", 0),
                        "leverage": zone.get("leverage_concentration", "unknown")
                    })
                
                return {
                    "success": True,
                    "symbol": symbol.upper(),
                    "heatmap": {
                        "levels": levels,
                        "currentPrice": current_price,
                        "long_short_ratio": data.get("long_short_ratio", 1),
                        "cascade_bias": data.get("cascade_bias", "NEUTRAL"),
                        "open_interest_usd": data.get("open_interest_usd", 0)
                    },
                    "source": "Helsinki"
                }
    except Exception as e:
        logger.error(f"Helsinki heatmap error: {e}")
    
    # Fallback to Coinglass
    try:
        result = await coinglass.get_liquidation_map(symbol.upper())
        
        if result.success:
            return {
                "success": True,
                "symbol": symbol.upper(),
                "heatmap": result.data,
                "latency_ms": result.latency_ms,
                "source": "Coinglass"
            }
    except Exception as e:
        logger.error(f"Coinglass heatmap error: {e}")
    
    return {"success": False, "error": "Both sources failed", "heatmap": None}


@app.get("/api/coinglass/liquidations/{symbol}")
async def get_coinglass_liquidations(symbol: str = "BTC", interval: str = "h1", limit: int = 24):
    """Get liquidation history from Coinglass."""
    try:
        result = await coinglass.get_liquidation_history(symbol.upper(), interval, limit)
        
        if not result.success:
            return {"success": False, "error": result.error}
        
        return {
            "success": True,
            "symbol": symbol.upper(),
            "liquidations": result.data,
            "latency_ms": result.latency_ms
        }
    except Exception as e:
        logger.error(f"Liquidation history error: {e}")
        return {"success": False, "error": str(e)}


@app.get("/api/coinglass/overview/{symbol}")
async def get_coinglass_overview(symbol: str = "BTC"):
    """Get comprehensive market data from Coinglass."""
    try:
        overview = await coinglass.get_market_overview(symbol.upper())
        return {"success": True, "symbol": symbol.upper(), "data": overview}
    except Exception as e:
        logger.error(f"Coinglass overview error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# ETF FLOWS API (Coinglass Premium)
# =============================================================================

@app.get("/api/etf-flows")
async def get_etf_flows():
    """Get Bitcoin ETF flows - IBIT, FBTC, GBTC, etc."""
    try:
        result = await coinglass.get_bitcoin_etf()
        
        if result.success and result.data:
            # Parse and format ETF data
            etfs = []
            total_flow = 0
            
            for etf in result.data if isinstance(result.data, list) else [result.data]:
                flow_24h = etf.get("h24Flow", etf.get("flow24h", 0))
                total_btc = etf.get("totalBtc", etf.get("total_btc", 0))
                etfs.append({
                    "name": etf.get("name", "Unknown"),
                    "totalBtc": total_btc,
                    "flow24h": flow_24h,
                    "flowUsd": flow_24h * 98000,  # Approximate
                })
                total_flow += flow_24h
            
            return {
                "success": True,
                "etfs": etfs,
                "totalFlow24h": total_flow,
                "totalFlowUsd": total_flow * 98000,
                "signal": "BULLISH" if total_flow > 0 else "BEARISH" if total_flow < 0 else "NEUTRAL",
                "latency_ms": result.latency_ms
            }
        
        # Fallback mock data if API fails
        return {
            "success": True,
            "etfs": [
                {"name": "IBIT", "totalBtc": 285000, "flow24h": 2340, "flowUsd": 229320000},
                {"name": "FBTC", "totalBtc": 175000, "flow24h": 890, "flowUsd": 87220000},
                {"name": "GBTC", "totalBtc": 215000, "flow24h": -120, "flowUsd": -11760000},
                {"name": "ARKB", "totalBtc": 48000, "flow24h": 450, "flowUsd": 44100000},
            ],
            "totalFlow24h": 3560,
            "totalFlowUsd": 348880000,
            "signal": "BULLISH",
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"ETF flows error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# TOP TRADER SENTIMENT API (Coinglass Premium)
# =============================================================================

@app.get("/api/top-traders/{symbol}")
async def get_top_traders(symbol: str = "BTC"):
    """Get top trader (whale) long/short sentiment."""
    import asyncio
    
    try:
        # Fetch both top trader and global sentiment
        top_result, global_result = await asyncio.gather(
            coinglass.get_top_trader_sentiment(symbol.upper()),
            coinglass.get_long_short_ratio(symbol.upper()),
            return_exceptions=True
        )
        
        # Parse top trader data (whales)
        top_long = 50
        top_short = 50
        if hasattr(top_result, 'success') and top_result.success and top_result.data:
            data = top_result.data[-1] if isinstance(top_result.data, list) and len(top_result.data) > 0 else top_result.data
            # Handle different field names from Coinglass
            top_long = data.get("longAccount", data.get("longRatio", data.get("longShortRatio", 50)))
            top_short = data.get("shortAccount", data.get("shortRatio", 100 - top_long))
            # Convert ratio to percentage if needed
            if top_long > 1 and top_long < 5:  # It's a ratio like 1.5
                total = top_long + 1
                top_long = (top_long / total) * 100
                top_short = 100 - top_long
        
        # Parse global (retail) data
        retail_long = 50
        retail_short = 50
        if hasattr(global_result, 'success') and global_result.success and global_result.data:
            data = global_result.data[-1] if isinstance(global_result.data, list) and len(global_result.data) > 0 else global_result.data
            retail_long = data.get("longAccount", data.get("longRatio", data.get("longShortRatio", 50)))
            retail_short = data.get("shortAccount", data.get("shortRatio", 100 - retail_long))
            if retail_long > 1 and retail_long < 5:
                total = retail_long + 1
                retail_long = (retail_long / total) * 100
                retail_short = 100 - retail_long
        
        # Detect divergence
        divergence = "NONE"
        if top_long > 55 and retail_long > 70:
            divergence = "CROWDED_LONG"
        elif top_short > 55 and retail_short > 70:
            divergence = "CROWDED_SHORT"
        elif abs(top_long - retail_long) > 15:
            if top_long > retail_long:
                divergence = "SMART_MONEY_LONG"
            else:
                divergence = "SMART_MONEY_SHORT"
        
        return {
            "success": True,
            "symbol": symbol.upper(),
            "topTraders": {
                "long": round(top_long, 1),
                "short": round(top_short, 1),
            },
            "retail": {
                "long": round(retail_long, 1),
                "short": round(retail_short, 1),
            },
            "divergence": divergence,
            "signal": "BULLISH" if divergence == "SMART_MONEY_LONG" else "BEARISH" if divergence == "SMART_MONEY_SHORT" else "NEUTRAL"
        }
    except Exception as e:
        logger.error(f"Top traders error: {e}")
        return {
            "success": True,
            "symbol": symbol.upper(),
            "topTraders": {"long": 58.2, "short": 41.8},
            "retail": {"long": 72.4, "short": 27.6},
            "divergence": "SMART_MONEY_LONG",
            "signal": "BULLISH",
            "source": "fallback"
        }


# =============================================================================
# OPTIONS MAX PAIN API (Coinglass Premium)
# =============================================================================

@app.get("/api/options/{symbol}")
async def get_options_data(symbol: str = "BTC"):
    """Get options data - max pain, put/call ratio."""
    import asyncio
    
    try:
        # Fetch both options info and max pain in parallel
        info_result, pain_result = await asyncio.gather(
            coinglass.get_options_info(symbol.upper()),
            coinglass.get_options_max_pain(symbol.upper()),
            return_exceptions=True
        )
        
        max_pain = 0
        put_call = 1.0
        total_oi = 0
        volume = 0
        
        # Parse options info
        if isinstance(info_result, CoinglassResponse) and info_result.success and info_result.data:
            data = info_result.data
            # Handle array response - Coinglass returns array with "All" aggregate
            if isinstance(data, list):
                for item in data:
                    if item.get("exchange") == "All" or item.get("exchangeName") == "All":
                        put_call = item.get("putCallRatio", item.get("pcRatio", 1.0))
                        total_oi = item.get("totalOpenInterest", item.get("openInterest", 0))
                        volume = item.get("totalVolume24h", item.get("volume24h", 0))
                        break
                if not total_oi and len(data) > 0:
                    # Sum all exchanges if no "All" found
                    put_call = data[0].get("putCallRatio", data[0].get("pcRatio", 1.0))
                    total_oi = sum(d.get("openInterest", 0) for d in data)
                    volume = sum(d.get("volume24h", 0) for d in data)
            else:
                put_call = data.get("putCallRatio", data.get("pcRatio", 1.0))
                total_oi = data.get("totalOpenInterest", data.get("openInterest", 0))
                volume = data.get("totalVolume24h", data.get("volume24h", 0))
        
        # Parse max pain
        if isinstance(pain_result, CoinglassResponse) and pain_result.success and pain_result.data:
            data = pain_result.data
            # Get the nearest expiry max pain
            if isinstance(data, list) and len(data) > 0:
                # Sort by expiry date, get nearest
                max_pain = data[0].get("maxPain", data[0].get("maxPainPrice", 0))
            elif isinstance(data, dict):
                max_pain = data.get("maxPain", data.get("maxPainPrice", 0))
        
        if max_pain > 0 or put_call != 1.0 or total_oi > 0:
            return {
                "success": True,
                "symbol": symbol.upper(),
                "maxPain": max_pain,
                "putCallRatio": round(put_call, 2),
                "totalOI": total_oi,
                "volume24h": volume,
                "signal": "BULLISH" if put_call < 0.9 else "BEARISH" if put_call > 1.1 else "NEUTRAL"
            }
        
        # Fallback if both fail
        return {
            "success": True,
            "symbol": symbol.upper(),
            "maxPain": 95000,
            "putCallRatio": 0.78,
            "totalOI": 12500000000,
            "volume24h": 890000000,
            "signal": "BULLISH",
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"Options error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# FUNDING ARBITRAGE API (Coinglass Premium)
# =============================================================================

@app.get("/api/funding-arb/{symbol}")
async def get_funding_arbitrage(symbol: str = "BTC"):
    """Get funding rates by exchange for arbitrage opportunities."""
    try:
        result = await coinglass.get_funding_rates(symbol.upper())
        
        if result.success and result.data:
            exchanges = []
            rates = []
            
            for ex in result.data if isinstance(result.data, list) else [result.data]:
                rate = ex.get("fundingRate", 0)
                exchanges.append({
                    "exchange": ex.get("exchange", "Unknown"),
                    "symbol": ex.get("symbol", f"{symbol}USDT"),
                    "rate": rate,
                    "ratePercent": rate * 100,
                    "nextFunding": ex.get("nextFundingTime", 0)
                })
                rates.append(rate)
            
            # Sort by rate
            exchanges.sort(key=lambda x: x["rate"], reverse=True)
            
            # Calculate spread
            spread = max(rates) - min(rates) if rates else 0
            
            return {
                "success": True,
                "symbol": symbol.upper(),
                "exchanges": exchanges[:8],  # Top 8
                "spread": spread,
                "spreadPercent": spread * 100,
                "highestRate": exchanges[0] if exchanges else None,
                "lowestRate": exchanges[-1] if exchanges else None,
                "arbOpportunity": spread > 0.0001,  # 0.01% threshold
                "latency_ms": result.latency_ms
            }
        
        # Fallback
        return {
            "success": True,
            "symbol": symbol.upper(),
            "exchanges": [
                {"exchange": "Binance", "rate": 0.00012, "ratePercent": 0.012},
                {"exchange": "OKX", "rate": 0.00010, "ratePercent": 0.010},
                {"exchange": "Bybit", "rate": 0.00011, "ratePercent": 0.011},
                {"exchange": "dYdX", "rate": -0.00003, "ratePercent": -0.003},
            ],
            "spread": 0.00015,
            "spreadPercent": 0.015,
            "arbOpportunity": True,
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"Funding arb error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# OI BY EXCHANGE API (Coinglass Premium)
# =============================================================================

@app.get("/api/oi-exchange/{symbol}")
async def get_oi_by_exchange(symbol: str = "BTC"):
    """Get open interest broken down by exchange."""
    try:
        result = await coinglass.get_open_interest(symbol.upper())
        
        if result.success and result.data:
            exchanges = []
            total_oi = 0
            
            for ex in result.data if isinstance(result.data, list) else [result.data]:
                oi = ex.get("openInterest", 0)
                exchanges.append({
                    "exchange": ex.get("exchange", "Unknown"),
                    "oi": oi,
                    "oiFormatted": f"${oi/1e9:.2f}B" if oi > 1e9 else f"${oi/1e6:.0f}M",
                    "change24h": ex.get("h24Change", 0),
                })
                total_oi += oi
            
            # Sort by OI
            exchanges.sort(key=lambda x: x["oi"], reverse=True)
            
            # Calculate percentages
            for ex in exchanges:
                ex["percentage"] = (ex["oi"] / total_oi * 100) if total_oi > 0 else 0
            
            return {
                "success": True,
                "symbol": symbol.upper(),
                "exchanges": exchanges[:8],
                "totalOI": total_oi,
                "totalOIFormatted": f"${total_oi/1e9:.2f}B" if total_oi > 1e9 else f"${total_oi/1e6:.0f}M",
                "latency_ms": result.latency_ms
            }
        
        # Fallback
        return {
            "success": True,
            "symbol": symbol.upper(),
            "exchanges": [
                {"exchange": "Binance", "oi": 4200000000, "oiFormatted": "$4.2B", "change24h": 2.3, "percentage": 45},
                {"exchange": "CME", "oi": 1800000000, "oiFormatted": "$1.8B", "change24h": -1.2, "percentage": 19},
                {"exchange": "OKX", "oi": 1100000000, "oiFormatted": "$1.1B", "change24h": 0.8, "percentage": 12},
                {"exchange": "Bybit", "oi": 900000000, "oiFormatted": "$0.9B", "change24h": 1.5, "percentage": 10},
                {"exchange": "Bitget", "oi": 600000000, "oiFormatted": "$0.6B", "change24h": 0.5, "percentage": 6},
            ],
            "totalOI": 9400000000,
            "totalOIFormatted": "$9.4B",
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"OI by exchange error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# TAKER BUY/SELL API (Coinglass Premium)
# =============================================================================

@app.get("/api/taker-ratio/{symbol}")
async def get_taker_ratio(symbol: str = "BTC"):
    """Get taker buy/sell ratio - real-time order flow pressure."""
    try:
        result = await coinglass.get_taker_buy_sell(symbol.upper())
        
        if result.success and result.data:
            data = result.data
            
            # Handle array response - sum across exchanges
            total_buy = 0
            total_sell = 0
            
            if isinstance(data, list):
                for ex in data:
                    total_buy += ex.get("buyVolUsd", ex.get("buyVol", 0))
                    total_sell += ex.get("sellVolUsd", ex.get("sellVol", 0))
            else:
                total_buy = data.get("buyVolUsd", data.get("buyVol", data.get("buyRatio", 0.5)))
                total_sell = data.get("sellVolUsd", data.get("sellVol", data.get("sellRatio", 0.5)))
            
            total = total_buy + total_sell
            buy_ratio = total_buy / total if total > 0 else 0.5
            sell_ratio = total_sell / total if total > 0 else 0.5
            
            return {
                "success": True,
                "symbol": symbol.upper(),
                "buyRatio": round(buy_ratio, 4),
                "sellRatio": round(sell_ratio, 4),
                "netFlow": "BUY" if buy_ratio > sell_ratio else "SELL",
                "buyPercent": round(buy_ratio * 100, 1),
                "sellPercent": round(sell_ratio * 100, 1),
                "buyVolUsd": total_buy,
                "sellVolUsd": total_sell,
                "signal": "BULLISH" if buy_ratio > 0.55 else "BEARISH" if sell_ratio > 0.55 else "NEUTRAL",
                "latency_ms": result.latency_ms
            }
        
        # Fallback
        return {
            "success": True,
            "symbol": symbol.upper(),
            "buyRatio": 0.52,
            "sellRatio": 0.48,
            "netFlow": "BUY",
            "buyPercent": 52,
            "sellPercent": 48,
            "signal": "NEUTRAL",
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"Taker ratio error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# EXCHANGE NET FLOW API (Coinglass + Whale Alert fallback)
# =============================================================================

@app.get("/api/exchange-flow/{symbol}")
async def get_exchange_net_flow(symbol: str = "BTC", hours: int = 24):
    """Get net exchange inflow/outflow for a symbol."""
    init_clients()
    
    # Try Coinglass first (more reliable, no rate limit issues)
    try:
        result = await coinglass.get_exchange_netflow(symbol.upper())
        
        if result.success and result.data:
            data = result.data
            
            # Parse Coinglass format - may be array of exchanges
            total_inflow = 0
            total_outflow = 0
            
            if isinstance(data, list):
                for ex in data:
                    inflow = ex.get("inflow", ex.get("inflowUsd", 0))
                    outflow = ex.get("outflow", ex.get("outflowUsd", 0))
                    total_inflow += inflow
                    total_outflow += outflow
            else:
                total_inflow = data.get("inflow", data.get("totalInflow", 0))
                total_outflow = data.get("outflow", data.get("totalOutflow", 0))
            
            net_flow = total_outflow - total_inflow
            
            return {
                "success": True,
                "symbol": symbol.upper(),
                "hours": hours,
                "inflows": total_inflow,
                "inflowsFormatted": f"${total_inflow/1e6:.1f}M" if total_inflow > 1e6 else f"${total_inflow/1e3:.0f}K",
                "outflows": total_outflow,
                "outflowsFormatted": f"${total_outflow/1e6:.1f}M" if total_outflow > 1e6 else f"${total_outflow/1e3:.0f}K",
                "netFlow": net_flow,
                "netFlowFormatted": f"${abs(net_flow)/1e6:.1f}M" if abs(net_flow) > 1e6 else f"${abs(net_flow)/1e3:.0f}K",
                "direction": "OUTFLOW" if net_flow > 0 else "INFLOW",
                "signal": "BULLISH" if net_flow > 0 else "BEARISH",
                "source": "coinglass"
            }
    except Exception as e:
        logger.warning(f"Coinglass exchange flow failed: {e}")
    
    # Fallback to Whale Alert
    try:
        flows = await whale_alert.get_exchange_flows(symbol=symbol.lower(), hours=hours)
        
        if "error" not in flows:
            net_flow = flows.get("net_flow_usd", 0)
            inflows = flows.get("inflows_usd", 0)
            outflows = flows.get("outflows_usd", 0)
            
            return {
                "success": True,
                "symbol": symbol.upper(),
                "hours": hours,
                "inflows": inflows,
                "inflowsFormatted": f"${inflows/1e6:.1f}M" if inflows > 1e6 else f"${inflows/1e3:.0f}K",
                "outflows": outflows,
                "outflowsFormatted": f"${outflows/1e6:.1f}M" if outflows > 1e6 else f"${outflows/1e3:.0f}K",
                "netFlow": net_flow,
                "netFlowFormatted": f"${abs(net_flow)/1e6:.1f}M" if abs(net_flow) > 1e6 else f"${abs(net_flow)/1e3:.0f}K",
                "direction": "OUTFLOW" if net_flow > 0 else "INFLOW",
                "signal": "BULLISH" if net_flow > 0 else "BEARISH",
                "exchangeBreakdown": flows.get("exchange_breakdown", {}),
                "txCount": flows.get("transaction_count", 0),
                "source": "whale_alert"
            }
    except Exception as e:
        logger.warning(f"Whale Alert exchange flow failed: {e}")
    
    # Fallback if both fail
    return {
        "success": True,
        "symbol": symbol.upper(),
        "hours": hours,
        "inflows": 89000000,
        "inflowsFormatted": "$89M",
        "outflows": 204000000,
        "outflowsFormatted": "$204M",
        "netFlow": 115000000,
        "netFlowFormatted": "$115M",
        "direction": "OUTFLOW",
        "signal": "BULLISH",
        "source": "fallback"
    }


# =============================================================================
# LIQUIDATION BY EXCHANGE API (Coinglass Premium)
# =============================================================================

@app.get("/api/liq-exchange/{symbol}")
async def get_liquidation_by_exchange(symbol: str = "BTC"):
    """Get liquidations broken down by exchange."""
    try:
        result = await coinglass.get_liquidation_by_exchange(symbol.upper())
        
        if result.success and result.data:
            exchanges = []
            total_long = 0
            total_short = 0
            
            for ex in result.data if isinstance(result.data, list) else [result.data]:
                long_liq = ex.get("h24LongLiqUsd", 0)
                short_liq = ex.get("h24ShortLiqUsd", 0)
                exchanges.append({
                    "exchange": ex.get("exchange", "Unknown"),
                    "longLiq": long_liq,
                    "shortLiq": short_liq,
                    "total": long_liq + short_liq,
                    "longPercent": (long_liq / (long_liq + short_liq) * 100) if (long_liq + short_liq) > 0 else 50,
                })
                total_long += long_liq
                total_short += short_liq
            
            # Sort by total
            exchanges.sort(key=lambda x: x["total"], reverse=True)
            
            return {
                "success": True,
                "symbol": symbol.upper(),
                "exchanges": exchanges[:6],
                "totalLongLiq": total_long,
                "totalShortLiq": total_short,
                "total24h": total_long + total_short,
                "dominantSide": "LONGS" if total_long > total_short else "SHORTS",
                "latency_ms": result.latency_ms
            }
        
        # Fallback
        return {
            "success": True,
            "symbol": symbol.upper(),
            "exchanges": [
                {"exchange": "Binance", "longLiq": 45000000, "shortLiq": 32000000, "total": 77000000, "longPercent": 58.4},
                {"exchange": "OKX", "longLiq": 23000000, "shortLiq": 18000000, "total": 41000000, "longPercent": 56.1},
                {"exchange": "Bybit", "longLiq": 15000000, "shortLiq": 12000000, "total": 27000000, "longPercent": 55.6},
            ],
            "totalLongLiq": 83000000,
            "totalShortLiq": 62000000,
            "total24h": 145000000,
            "dominantSide": "LONGS",
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"Liq by exchange error: {e}")
        return {"success": False, "error": str(e)}


# =============================================================================
# VOLATILITY REGIME ANALYSIS API
# =============================================================================

@app.get("/api/volatility-regime/{symbol}")
async def get_volatility_regime(symbol: str = "BTC"):
    """
    Analyze volatility regime - compression vs expansion.
    Predicts when volatility regime is about to change.
    """
    init_clients()
    import httpx
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    
    try:
        # Fetch volatility data from Helsinki
        async with httpx.AsyncClient(timeout=5.0) as client:
            vol_res = await client.get(f"{base}/quant/volatility/{symbol.upper()}")
            vol_data = vol_res.json()
            
            # Get recent price data for ATR calculation
            price_res = await client.get(f"https://min-api.cryptocompare.com/data/v2/histoday?fsym={symbol.upper()}&tsym=USD&limit=14")
            price_data = price_res.json()
        
        # Parse volatility
        current_vol = vol_data.get("daily_volatility_pct", vol_data.get("volatility_pct", 2.0))
        atr_pct = vol_data.get("atr_pct", current_vol)
        regime = vol_data.get("regime", vol_data.get("current_regime", "NORMAL"))
        
        # Calculate Bollinger Width from price data
        prices = [c.get("close", 0) for c in price_data.get("Data", {}).get("Data", [])]
        if len(prices) >= 14:
            import statistics
            mean_price = statistics.mean(prices[-20:] if len(prices) >= 20 else prices)
            std_dev = statistics.stdev(prices[-20:] if len(prices) >= 20 else prices)
            bb_width = (std_dev / mean_price) * 100 * 4  # 2 std devs * 2 sides
        else:
            bb_width = 4.0  # Default
        
        # Determine compression status
        is_compression = bb_width < 5.0 or atr_pct < 2.0
        
        # Estimate days in current regime (simplified - would need historical tracking)
        days_in_regime = 3 if is_compression else 1
        
        # Calculate expansion probability
        if is_compression:
            # Longer compression = higher probability of expansion
            expansion_prob = min(90, 40 + (days_in_regime * 10))
        else:
            expansion_prob = 20
        
        # Generate recommendation
        if is_compression and expansion_prob > 60:
            recommendation = [
                "Reduce position size 50% (whipsaws likely)",
                "Widen stops OR wait for direction confirmation",
                "Set breakout alerts above/below range"
            ]
            regime_display = "COMPRESSION"
            warning = "EXPANSION IMMINENT"
        elif regime == "HIGH" or regime == "EXTREME":
            recommendation = [
                "Use smaller position sizes",
                "Take profits more aggressively",
                "Expect larger swings"
            ]
            regime_display = "EXPANSION"
            warning = None
        else:
            recommendation = [
                "Standard position sizing OK",
                "Normal stop distances",
                "Trend following strategies preferred"
            ]
            regime_display = "NORMAL"
            warning = None
        
        # Determine direction bias
        if prices and len(prices) >= 3:
            recent_change = (prices[-1] - prices[-3]) / prices[-3] * 100 if prices[-3] > 0 else 0
            direction_bias = "BULLISH" if recent_change > 1 else "BEARISH" if recent_change < -1 else "UNKNOWN"
        else:
            direction_bias = "UNKNOWN"
        
        return {
            "success": True,
            "symbol": symbol.upper(),
            "regime": regime_display,
            "atrPercent": round(atr_pct, 2),
            "bollingerWidth": round(bb_width, 2),
            "daysInRegime": days_in_regime,
            "isCompression": is_compression,
            "expansionProbability": expansion_prob,
            "warning": warning,
            "directionBias": direction_bias,
            "recommendation": recommendation,
            "signal": "CAUTION" if is_compression else "NORMAL"
        }
        
    except Exception as e:
        logger.error(f"Volatility regime error: {e}")
        # Fallback with realistic data
        return {
            "success": True,
            "symbol": symbol.upper(),
            "regime": "COMPRESSION",
            "atrPercent": 1.8,
            "bollingerWidth": 3.2,
            "daysInRegime": 4,
            "isCompression": True,
            "expansionProbability": 72,
            "warning": "EXPANSION IMMINENT",
            "directionBias": "UNKNOWN",
            "recommendation": [
                "Reduce position size 50% (whipsaws likely)",
                "Widen stops OR wait for direction confirmation",
                "Set alerts at key breakout levels"
            ],
            "signal": "CAUTION",
            "source": "fallback"
        }


# =============================================================================
# MM MAGNET (Market Maker Target Estimation) API
# =============================================================================

@app.get("/api/mm-magnet/{symbol}")
async def get_mm_magnet(symbol: str = "BTC"):
    """
    Estimate where market makers want to push price.
    
    Uses weighted signals:
    - Options Max Pain (30%)
    - Liquidation Cluster Hunting (25%)
    - Funding Rate Mean Reversion (15%)
    - Top Trader vs Retail Divergence (15%)
    - ETF Flow Direction (15%)
    """
    init_clients()
    import asyncio
    import httpx
    base = helsinki.base_url if helsinki else "http://77.42.29.188:5002"
    
    try:
        # Fetch all required data in parallel
        async with httpx.AsyncClient(timeout=5.0) as client:
            # Get current price
            price_task = client.get(f"https://min-api.cryptocompare.com/data/pricemultifull?fsyms={symbol.upper()}&tsyms=USD")
            
            # Get liquidation data from Helsinki
            liq_task = client.get(f"{base}/quant/liquidation-estimate/{symbol.upper()}")
            
            # Get funding data
            funding_task = client.get(f"{base}/quant/liquidation-estimate/{symbol.upper()}")  # Contains funding
            
            price_res, liq_res, funding_res = await asyncio.gather(
                price_task, liq_task, funding_task,
                return_exceptions=True
            )
        
        # Parse current price
        current_price = 0
        if not isinstance(price_res, Exception):
            price_data = price_res.json()
            current_price = price_data.get("RAW", {}).get(symbol.upper(), {}).get("USD", {}).get("PRICE", 0)
        
        # Parse liquidation data
        long_liq_cluster = {"price": current_price * 0.96, "usd": 837000000}
        short_liq_cluster = {"price": current_price * 1.04, "usd": 440000000}
        ls_ratio = 1.9
        
        if not isinstance(liq_res, Exception):
            liq_data = liq_res.json()
            ls_ratio = liq_data.get("long_short_ratio", 1.9)
            
            # Get downside (long) liquidation zones
            downside_zones = liq_data.get("downside_liquidation_zones", [])
            if downside_zones:
                biggest_long = max(downside_zones, key=lambda x: x.get("estimated_usd_at_risk", 0))
                long_liq_cluster = {
                    "price": biggest_long.get("price", current_price * 0.96),
                    "usd": biggest_long.get("estimated_usd_at_risk", 837000000)
                }
            
            # Get upside (short) liquidation zones
            upside_zones = liq_data.get("upside_liquidation_zones", [])
            if upside_zones:
                biggest_short = max(upside_zones, key=lambda x: x.get("estimated_usd_at_risk", 0))
                short_liq_cluster = {
                    "price": biggest_short.get("price", current_price * 1.04),
                    "usd": biggest_short.get("estimated_usd_at_risk", 440000000)
                }
        
        # Parse funding rate
        funding_rate = 0.0001
        if not isinstance(funding_res, Exception):
            funding_data = funding_res.json()
            funding_rate = funding_data.get("funding_rate_pct", 0.01) / 100
        
        # === SIGNAL CALCULATIONS ===
        
        # Signal 1: Max Pain (mock - would come from Coinglass options API)
        # Typically max pain is near current price +-5%
        max_pain_price = current_price * 1.02  # Mock: slightly above current
        max_pain_signal = ((max_pain_price - current_price) / current_price) if current_price > 0 else 0
        max_pain_signal = max(-1, min(1, max_pain_signal * 10))  # Scale to -1 to 1
        
        # Signal 2: Liquidation Hunt
        # Which cluster has more money at risk? MM hunt the bigger one
        if long_liq_cluster["usd"] > short_liq_cluster["usd"] * 1.3:
            liq_signal = -1.0  # Hunt longs (push down)
            liq_target = long_liq_cluster["price"]
        elif short_liq_cluster["usd"] > long_liq_cluster["usd"] * 1.3:
            liq_signal = 1.0  # Hunt shorts (push up)
            liq_target = short_liq_cluster["price"]
        else:
            liq_signal = 0.0  # Balanced
            liq_target = current_price
        
        # Signal 3: Funding Rate
        if funding_rate > 0.0003:  # Very high positive funding
            funding_signal = -0.8  # Longs paying too much, expect dump
        elif funding_rate > 0.0001:
            funding_signal = -0.3
        elif funding_rate < -0.0001:
            funding_signal = 0.5  # Shorts paying, expect pump
        else:
            funding_signal = 0.0
        
        # Signal 4: L/S Ratio Divergence
        if ls_ratio > 1.5:  # Way more longs
            divergence_signal = -0.7  # Fade the crowd
        elif ls_ratio < 0.7:  # Way more shorts
            divergence_signal = 0.7
        else:
            divergence_signal = 0.0
        
        # Signal 5: ETF Flows (mock - would come from Coinglass)
        etf_signal = 0.3  # Slight bullish (mock inflows)
        
        # === COMBINE SIGNALS ===
        weighted_signal = (
            max_pain_signal * 0.30 +
            liq_signal * 0.25 +
            funding_signal * 0.15 +
            divergence_signal * 0.15 +
            etf_signal * 0.15
        )
        
        # === DETERMINE TARGET ===
        if weighted_signal > 0.25:
            direction = "BULLISH"
            confidence = min(85, int(50 + abs(weighted_signal) * 50))
            primary_target = short_liq_cluster["price"]
        elif weighted_signal < -0.25:
            direction = "BEARISH"
            confidence = min(85, int(50 + abs(weighted_signal) * 50))
            primary_target = long_liq_cluster["price"]
        else:
            direction = "NEUTRAL"
            confidence = 40
            primary_target = max_pain_price
        
        # Calculate distance
        target_distance = ((primary_target - current_price) / current_price * 100) if current_price > 0 else 0
        
        # Time horizon based on funding interval
        time_horizon = "4-8h (next funding)"
        
        return {
            "success": True,
            "symbol": symbol.upper(),
            "currentPrice": current_price,
            "direction": direction,
            "target": primary_target,
            "targetFormatted": f"${primary_target:,.0f}",
            "targetDistance": round(target_distance, 1),
            "confidence": confidence,
            "timeHorizon": time_horizon,
            "weightedSignal": round(weighted_signal, 2),
            "signals": {
                "maxPain": {"value": round(max_pain_signal, 2), "label": f"up to ${max_pain_price:,.0f}"},
                "liqHunt": {"value": round(liq_signal, 2), "label": f"${long_liq_cluster['usd']/1e6:.0f}M longs" if liq_signal < 0 else f"${short_liq_cluster['usd']/1e6:.0f}M shorts"},
                "funding": {"value": round(funding_signal, 2), "label": "longs pay" if funding_signal < 0 else "shorts pay" if funding_signal > 0 else "neutral"},
                "divergence": {"value": round(divergence_signal, 2), "label": "fade longs" if divergence_signal < 0 else "fade shorts" if divergence_signal > 0 else "balanced"},
                "etfFlows": {"value": round(etf_signal, 2), "label": "inflows" if etf_signal > 0 else "outflows"}
            }
        }
        
    except Exception as e:
        logger.error(f"MM Magnet error: {e}")
        # Fallback with realistic mock data
        return {
            "success": True,
            "symbol": symbol.upper(),
            "currentPrice": 83700,
            "direction": "BEARISH",
            "target": 80400,
            "targetFormatted": "$80,400",
            "targetDistance": -4.0,
            "confidence": 65,
            "timeHorizon": "4-8h (next funding)",
            "weightedSignal": -0.42,
            "signals": {
                "maxPain": {"value": 0.3, "label": "up to $85K"},
                "liqHunt": {"value": -1.0, "label": "$837M longs"},
                "funding": {"value": -0.6, "label": "longs pay"},
                "divergence": {"value": -0.8, "label": "fade retail"},
                "etfFlows": {"value": 0.6, "label": "inflows"}
            },
            "source": "fallback"
        }


# =============================================================================
# ON-CHAIN INTEL ENDPOINTS (LIVE from Coinglass + Helsinki)
# =============================================================================

@app.get("/api/onchain")
async def get_onchain_data():
    """
    Get on-chain intelligence data from Coinglass derivatives data.
    
    NOTE: True exchange reserves require Glassnode ($799/mo) or CryptoQuant.
    This uses Coinglass OI/liquidation data to infer on-chain activity.
    """
    import asyncio
    
    try:
        # Fetch REAL derivatives data from Coinglass
        btc_oi_task = coinglass.get_open_interest("BTC")
        eth_oi_task = coinglass.get_open_interest("ETH")
        btc_ls_task = coinglass.get_long_short_ratio("BTC")
        btc_liq_task = coinglass.get_liquidation_history("BTC", interval="h24", limit=1)
        
        btc_oi, eth_oi, btc_ls, btc_liq = await asyncio.gather(
            btc_oi_task, eth_oi_task, btc_ls_task, btc_liq_task,
            return_exceptions=True
        )
        
        # Parse BTC Open Interest (proxy for exchange activity)
        btc_total_oi = 0
        btc_oi_change = 0
        if isinstance(btc_oi, CoinglassResponse) and btc_oi.success and btc_oi.data:
            for ex in btc_oi.data if isinstance(btc_oi.data, list) else [btc_oi.data]:
                btc_total_oi += ex.get("openInterest", 0)
                btc_oi_change += ex.get("h24Change", 0)
        
        # Parse ETH Open Interest
        eth_total_oi = 0
        eth_oi_change = 0
        if isinstance(eth_oi, CoinglassResponse) and eth_oi.success and eth_oi.data:
            for ex in eth_oi.data if isinstance(eth_oi.data, list) else [eth_oi.data]:
                eth_total_oi += ex.get("openInterest", 0)
                eth_oi_change += ex.get("h24Change", 0)
        
        # Parse Long/Short ratio for whale activity inference
        long_pct = 50
        short_pct = 50
        if isinstance(btc_ls, CoinglassResponse) and btc_ls.success and btc_ls.data:
            latest = btc_ls.data[-1] if isinstance(btc_ls.data, list) and len(btc_ls.data) > 0 else btc_ls.data
            if latest:
                long_pct = latest.get("longAccount", 50)
                short_pct = latest.get("shortAccount", 50)
        
        # Parse 24h liquidations
        long_liq = 0
        short_liq = 0
        if isinstance(btc_liq, CoinglassResponse) and btc_liq.success and btc_liq.data:
            for item in btc_liq.data if isinstance(btc_liq.data, list) else [btc_liq.data]:
                long_liq += item.get("longLiquidationUsd", 0)
                short_liq += item.get("shortLiquidationUsd", 0)
        
        # Infer whale activity from OI change and L/S ratio
        # Increasing OI + more longs = accumulation
        # Decreasing OI + more shorts = distribution
        oi_trend = "RISING" if btc_oi_change > 2 else "FALLING" if btc_oi_change < -2 else "STABLE"
        whale_bias = "ACCUMULATION" if (btc_oi_change > 0 and long_pct > 55) else "DISTRIBUTION" if (btc_oi_change < 0 and short_pct > 55) else "NEUTRAL"
        
        # Determine overall signal
        signal = "BULLISH" if (oi_trend == "RISING" and long_pct > 52) else "BEARISH" if (oi_trend == "FALLING" and short_pct > 52) else "NEUTRAL"
        
        return {
            "success": True,
            "source": "Coinglass (Derivatives Proxy)",
            "note": "Exchange reserves require Glassnode API ($799/mo)",
            "openInterest": {
                "btc": {
                    "value": btc_total_oi,
                    "formatted": f"${btc_total_oi/1e9:.2f}B" if btc_total_oi > 1e9 else f"${btc_total_oi/1e6:.0f}M",
                    "change24h": round(btc_oi_change, 2),
                    "trend": oi_trend,
                    "barWidth": max(30, min(80, 55 + btc_oi_change * 2))
                },
                "eth": {
                    "value": eth_total_oi,
                    "formatted": f"${eth_total_oi/1e9:.2f}B" if eth_total_oi > 1e9 else f"${eth_total_oi/1e6:.0f}M",
                    "change24h": round(eth_oi_change, 2),
                    "trend": "RISING" if eth_oi_change > 2 else "FALLING" if eth_oi_change < -2 else "STABLE",
                    "barWidth": max(30, min(80, 55 + eth_oi_change * 2))
                }
            },
            "positionBias": {
                "longPct": round(long_pct, 1),
                "shortPct": round(short_pct, 1),
                "ratio": round(long_pct / short_pct, 2) if short_pct > 0 else 1,
                "dominant": "LONGS" if long_pct > 52 else "SHORTS" if short_pct > 52 else "BALANCED"
            },
            "liquidations24h": {
                "longLiq": long_liq,
                "longFormatted": f"${long_liq/1e6:.1f}M" if long_liq > 0 else "$0",
                "shortLiq": short_liq,
                "shortFormatted": f"${short_liq/1e6:.1f}M" if short_liq > 0 else "$0",
                "total": long_liq + short_liq,
                "totalFormatted": f"${(long_liq + short_liq)/1e6:.1f}M",
                "dominantSide": "LONGS" if long_liq > short_liq else "SHORTS"
            },
            "whaleActivity": {
                "phase": whale_bias,
                "signal": signal,
                "interpretation": f"OI {oi_trend.lower()}, {long_pct:.0f}% longs - {'Accumulation likely' if whale_bias == 'ACCUMULATION' else 'Distribution likely' if whale_bias == 'DISTRIBUTION' else 'Mixed signals'}",
                "barWidth": max(20, min(90, 50 + (long_pct - 50) * 2))
            },
            "marketSignal": {
                "oiTrend": oi_trend,
                "positionBias": "LONGS" if long_pct > 52 else "SHORTS" if short_pct > 52 else "BALANCED",
                "signal": signal,
                "interpretation": f"{'Bullish: Rising OI with long bias' if signal == 'BULLISH' else 'Bearish: Falling OI with short bias' if signal == 'BEARISH' else 'Neutral: Mixed signals'}"
            }
        }
        
    except Exception as e:
        logger.error(f"On-chain data error: {e}")
        return {
            "success": True,
            "exchangeReserves": {
                "btc": {"value": 2.1, "formatted": "2.1M", "change7d": -3.2, "barWidth": 65},
                "eth": {"value": 18.4, "formatted": "18.4M", "change7d": -1.8, "barWidth": 58}
            },
            "stablecoinFlows": {
                "usdt": {"value": 847e6, "formatted": "+$847M", "action": "MINTED"},
                "usdc": {"value": -124e6, "formatted": "-$124M", "action": "BURNED"},
                "netInflow": 723e6, "netFormatted": "+$723M"
            },
            "minerFlows": {"outflow24h": 342, "formatted": "342 BTC", "avg7d": 89, "delta": 284, "signal": "ELEVATED"},
            "dormantSupply": {"movedToday": 1247, "formatted": "1,247 BTC", "avg7d": 312, "delta": 300, "signal": "DISTRIBUTION"},
            "networkActivity": {"activeAddresses": 892000, "activeFormatted": "892K", "newAddresses": 42000, "newFormatted": "+42K", "txCount": 324000, "txFormatted": "324K"},
            "whaleWallets": {"netChange7d": 12847, "formatted": "+12,847 BTC", "phase": "ACCUMULATION", "barWidth": 72},
            "source": "fallback"
        }


# =============================================================================
# ORDER FLOW ENDPOINTS
# =============================================================================

@app.get("/api/orderflow/{symbol}")
async def get_orderflow_data(symbol: str = "BTC"):
    """Get live order flow intelligence - bid/ask imbalance, aggressor side, large orders."""
    try:
        # Fetch CVD and market data
        cvd_data = await helsinki.get(f"quant/cvd/{symbol}")
        market_data = await helsinki.get(f"quant/full/{symbol}")
        
        current_price = market_data.get("current_price", 83700)
        cvd_1h = cvd_data.get("cvd_1h_usd", 0)
        
        # Calculate bid/ask imbalance from available metrics
        ls_ratio = market_data.get("long_short_ratio", 1.5)
        
        # Simulate bid/ask based on L/S ratio
        bid_pct = min(75, max(35, 50 + (ls_ratio - 1) * 20))
        ask_pct = 100 - bid_pct
        imbalance_signal = "BUY" if bid_pct > 55 else "SELL" if bid_pct < 45 else "NEUTRAL"
        
        # Aggressor side calculation from CVD
        buyer_vol = abs(cvd_1h) if cvd_1h > 0 else random.uniform(15, 30) * 1e6
        seller_vol = abs(cvd_1h) if cvd_1h < 0 else random.uniform(10, 25) * 1e6
        total_vol = buyer_vol + seller_vol
        buyer_pct = buyer_vol / total_vol * 100 if total_vol > 0 else 50
        
        # Generate realistic large orders
        large_orders = []
        for i in range(5):
            is_buy = random.random() > 0.45
            order = {
                "time": f"{14-i//2}:{32-i*5:02d}",
                "side": "BUY" if is_buy else "SELL",
                "size": f"${random.uniform(0.5, 4):.1f}M",
                "price": f"@{current_price + random.randint(-200, 200):,.0f}"
            }
            large_orders.append(order)
        
        # CVD momentum
        cvd_value = cvd_1h if cvd_1h else random.uniform(-10, 15) * 1e6
        
        # Trade intensity - simulate based on volatility
        volatility = market_data.get("daily_volatility_pct", 2.0)
        intensity_pct = min(95, max(20, volatility * 30 + random.uniform(-10, 10)))
        intensity_signal = "HIGH" if intensity_pct > 70 else "ELEVATED" if intensity_pct > 50 else "NORMAL" if intensity_pct > 30 else "LOW"
        trades_per_sec = int(300 + intensity_pct * 10 + random.randint(-50, 50))
        
        # Spoofing detection (simulate occasional alerts)
        has_spoof = random.random() < 0.1
        spoof_status = "ALERT" if has_spoof else "CLEAR"
        
        return {
            "success": True,
            "symbol": symbol.upper(),
            "bidAskImbalance": {
                "bidPct": round(bid_pct, 0),
                "askPct": round(ask_pct, 0),
                "signal": imbalance_signal,
                "text": "STRONG BUY PRESSURE" if bid_pct > 60 else "BUY PRESSURE" if bid_pct > 55 else "STRONG SELL PRESSURE" if bid_pct < 40 else "SELL PRESSURE" if bid_pct < 45 else "BALANCED"
            },
            "aggressorSide": {
                "buyerVol": buyer_vol,
                "buyerFormatted": f"${buyer_vol/1e6:.1f}M",
                "buyerPct": round(buyer_pct, 0),
                "sellerVol": seller_vol,
                "sellerFormatted": f"${seller_vol/1e6:.1f}M",
                "sellerPct": round(100 - buyer_pct, 0),
                "delta": buyer_vol - seller_vol,
                "deltaFormatted": f"+${(buyer_vol-seller_vol)/1e6:.1f}M" if buyer_vol > seller_vol else f"-${abs(buyer_vol-seller_vol)/1e6:.1f}M"
            },
            "largeOrders": large_orders,
            "cvdMomentum": {
                "value": cvd_value,
                "formatted": f"+${cvd_value/1e6:.1f}M" if cvd_value > 0 else f"-${abs(cvd_value)/1e6:.1f}M",
                "isPositive": cvd_value > 0
            },
            "tradeIntensity": {
                "pct": round(intensity_pct, 0),
                "signal": intensity_signal,
                "tradesPerSec": trades_per_sec
            },
            "spoofDetection": {
                "status": spoof_status,
                "alerts": [{"time": "14:28", "side": "BUY", "size": "$8.2M", "note": "Pulled after 3s"}] if has_spoof else []
            }
        }
    except Exception as e:
        logger.error(f"Order flow error: {e}")
        return {
            "success": True,
            "symbol": symbol.upper(),
            "bidAskImbalance": {"bidPct": 62, "askPct": 38, "signal": "BUY", "text": "STRONG BUY PRESSURE"},
            "aggressorSide": {"buyerVol": 24.7e6, "buyerFormatted": "$24.7M", "buyerPct": 58, "sellerVol": 17.8e6, "sellerFormatted": "$17.8M", "sellerPct": 42, "delta": 6.9e6, "deltaFormatted": "+$6.9M"},
            "largeOrders": [
                {"time": "14:32", "side": "BUY", "size": "$2.4M", "price": "@83,420"},
                {"time": "14:28", "side": "SELL", "size": "$1.8M", "price": "@83,510"},
                {"time": "14:25", "side": "BUY", "size": "$3.1M", "price": "@83,380"}
            ],
            "cvdMomentum": {"value": 8.4e6, "formatted": "+$8.4M", "isPositive": True},
            "tradeIntensity": {"pct": 68, "signal": "ELEVATED", "tradesPerSec": 847},
            "spoofDetection": {"status": "CLEAR", "alerts": []},
            "source": "fallback"
        }


# =============================================================================
# SESSION & MACRO ANALYSIS
# =============================================================================

@app.get("/api/session")
async def get_session_analysis():
    """Get trading session analysis - time-of-day insights."""
    from datetime import datetime, timezone
    
    now = datetime.now(timezone.utc)
    hour = now.hour
    
    # Determine current session
    if 0 <= hour < 8:
        session = "ASIA"
        session_name = "Asia (Low Vol)"
        next_session = "London Open"
        hours_to_next = 8 - hour
    elif 8 <= hour < 13:
        session = "LONDON"
        session_name = "London (Med Vol)"
        next_session = "US Open"
        hours_to_next = 13 - hour
    elif 13 <= hour < 21:
        session = "US"
        session_name = "US (High Vol)"
        next_session = "Asia Open"
        hours_to_next = 24 - hour if hour >= 21 else 24 + (24 - hour)
    else:
        session = "LATE_US"
        session_name = "Late US (Low Vol)"
        next_session = "Asia Open"
        hours_to_next = 24 - hour
    
    recommendation = "Wait for US open" if session == "ASIA" else "Trade with trend" if session == "US" else "Scalp-friendly"
    
    return {
        "success": True,
        "current": session,
        "name": session_name,
        "next": f"{next_session} in {hours_to_next}h",
        "asiaAvg": "0.4%",
        "londonAvg": "0.8%",
        "usAvg": "1.2%",
        "recommendation": recommendation,
        "stats": {
            "bigMoves": "80% during US session",
            "avgAsia": 0.4,
            "avgLondon": 0.8,
            "avgUS": 1.2
        }
    }


@app.get("/api/macro")
async def get_macro_correlation():
    """Get macro market correlations."""
    import random
    
    # Simulate correlations (would connect to real data source)
    spx = round(random.uniform(0.65, 0.90), 2)
    nq = round(random.uniform(0.70, 0.92), 2)
    dxy = round(random.uniform(-0.80, -0.50), 2)
    gold = round(random.uniform(0.20, 0.55), 2)
    vix = round(random.uniform(-0.50, -0.20), 2)
    
    # Determine overall signal
    if spx > 0.7 and nq > 0.7:
        signal = "RISK-ON"
        note = "High equity correlation - Watch SPX"
    elif dxy < -0.6:
        signal = "RISK-ON"
        note = "DXY weakness bullish for BTC"
    else:
        signal = "NEUTRAL"
        note = "Mixed signals - Trade with caution"
    
    return {
        "success": True,
        "signal": signal,
        "correlations": {
            "spx": spx,
            "nq": nq,
            "dxy": dxy,
            "gold": gold,
            "vix": vix
        },
        "note": note
    }


# =============================================================================
# KELLY CRITERION & MONTE CARLO
# =============================================================================

@app.get("/api/kelly")
async def get_kelly_criterion():
    """Calculate Kelly criterion position sizing."""
    # Using session stats (would use real trade history)
    win_rate = 0.73
    avg_win = 2.1  # R-multiple
    avg_loss = 1.0
    
    # Kelly formula: K% = W - [(1-W) / R] where R = avg_win/avg_loss
    r_ratio = avg_win / avg_loss
    kelly = win_rate - ((1 - win_rate) / r_ratio)
    kelly_pct = max(0, min(kelly * 100, 25))  # Cap at 25%
    
    return {
        "success": True,
        "optimal": round(kelly_pct, 1),
        "half": round(kelly_pct / 2, 1),
        "quarter": round(kelly_pct / 4, 1),
        "winRate": int(win_rate * 100),
        "avgWin": f"+{avg_win}R",
        "avgLoss": f"-{avg_loss}R",
        "recommendation": "Use Half-Kelly (conservative)" if kelly_pct > 3 else "Size appropriately"
    }


@app.post("/api/monte-carlo")
async def run_monte_carlo(simulations: int = 50000):
    """Run Monte Carlo simulation for portfolio projections."""
    import random
    import statistics
    
    # Simulation parameters (would use real account data)
    starting_capital = 100000
    win_rate = 0.73
    avg_win_pct = 2.1
    avg_loss_pct = 1.0
    trades_to_simulate = 100
    position_size_pct = 1.2  # Half-Kelly
    
    final_capitals = []
    max_drawdowns = []
    
    for _ in range(min(simulations, 50000)):
        capital = starting_capital
        peak = capital
        max_dd = 0
        
        for _ in range(trades_to_simulate):
            if random.random() < win_rate:
                capital *= (1 + (avg_win_pct * position_size_pct / 100))
            else:
                capital *= (1 - (avg_loss_pct * position_size_pct / 100))
            
            if capital > peak:
                peak = capital
            dd = (peak - capital) / peak
            if dd > max_dd:
                max_dd = dd
        
        final_capitals.append(capital)
        max_drawdowns.append(max_dd)
    
    # Calculate statistics
    final_capitals.sort()
    ev = statistics.mean(final_capitals) - starting_capital
    conf_low = final_capitals[int(len(final_capitals) * 0.05)] - starting_capital
    conf_high = final_capitals[int(len(final_capitals) * 0.95)] - starting_capital
    ruin_count = sum(1 for c in final_capitals if c < starting_capital * 0.5)
    ruin_prob = (ruin_count / len(final_capitals)) * 100
    avg_max_dd = statistics.mean(max_drawdowns) * 100
    
    return {
        "success": True,
        "simulations": len(final_capitals),
        "ev": round(ev, 0),
        "evFormatted": f"+${ev:,.0f}" if ev > 0 else f"-${abs(ev):,.0f}",
        "confLow": round(conf_low, 0),
        "confLowFormatted": f"+${conf_low:,.0f}" if conf_low > 0 else f"-${abs(conf_low):,.0f}",
        "confHigh": round(conf_high, 0),
        "confHighFormatted": f"+${conf_high:,.0f}",
        "ruinProb": round(ruin_prob, 1),
        "maxDrawdown": round(avg_max_dd, 1)
    }


@app.get("/api/mcf-reports")
async def get_mcf_reports():
    """Get latest MCF Labs institutional reports."""
    # Placeholder - would connect to real report system
    return {
        "success": True,
        "latest": {
            "title": "BTC Accumulation Phase Confirmed: Smart Money Loading",
            "summary": "On-chain metrics show significant whale accumulation over past 72h. Exchange reserves at 3-year lows. Funding remains neutral suggesting room for upside.",
            "sentiment": "BULLISH",
            "confidence": "HIGH",
            "timestamp": "2 min ago"
        },
        "feed": [
            {"title": "ETH/BTC Ratio Analysis: Altcoin Season Incoming?", "sentiment": "NEUTRAL", "time": "1h"},
            {"title": "Derivatives Deep Dive: OI Surge Signals Volatility", "sentiment": "CAUTION", "time": "3h"},
            {"title": "Macro Weekly: Fed Pivot Implications for Crypto", "sentiment": "BULLISH", "time": "6h"},
            {"title": "Liquidation Map Analysis: Key Levels to Watch", "sentiment": "RISK ALERT", "time": "12h"}
        ]
    }


# =============================================================================
# SUPPORTED SYMBOLS
# =============================================================================

SUPPORTED_SYMBOLS = [
    {"symbol": "BTC", "name": "Bitcoin", "perp": "BTC-PERP"},
    {"symbol": "ETH", "name": "Ethereum", "perp": "ETH-PERP"},
    {"symbol": "SOL", "name": "Solana", "perp": "SOL-PERP"},
    {"symbol": "DOGE", "name": "Dogecoin", "perp": "DOGE-PERP"},
    {"symbol": "XRP", "name": "XRP", "perp": "XRP-PERP"},
    {"symbol": "AVAX", "name": "Avalanche", "perp": "AVAX-PERP"},
    {"symbol": "LINK", "name": "Chainlink", "perp": "LINK-PERP"},
    {"symbol": "MATIC", "name": "Polygon", "perp": "MATIC-PERP"},
    {"symbol": "ARB", "name": "Arbitrum", "perp": "ARB-PERP"},
    {"symbol": "OP", "name": "Optimism", "perp": "OP-PERP"},
    {"symbol": "APT", "name": "Aptos", "perp": "APT-PERP"},
    {"symbol": "SUI", "name": "Sui", "perp": "SUI-PERP"},
    {"symbol": "PEPE", "name": "Pepe", "perp": "PEPE-PERP"},
    {"symbol": "WIF", "name": "dogwifhat", "perp": "WIF-PERP"},
    {"symbol": "INJ", "name": "Injective", "perp": "INJ-PERP"},
]


@app.get("/api/symbols")
async def get_symbols():
    """Get list of supported trading symbols."""
    return {"symbols": SUPPORTED_SYMBOLS}


# =============================================================================
# LIVE NEWS API (CryptoPanic)
# =============================================================================

@app.get("/api/news")
async def get_live_news(limit: int = 10):
    """Get live breaking crypto news from multiple free sources."""
    import httpx
    from datetime import datetime
    import xml.etree.ElementTree as ET
    
    news_items = []
    
    async with httpx.AsyncClient(timeout=5.0) as client:
        # Source 1: CoinDesk RSS (free, no auth)
        try:
            res = await client.get("https://www.coindesk.com/arc/outboundfeeds/rss/")
            if res.status_code == 200:
                root = ET.fromstring(res.text)
                for item in root.findall('.//item')[:limit//2]:
                    title = item.find('title')
                    link = item.find('link')
                    pub_date = item.find('pubDate')
                    
                    if title is not None:
                        # Parse time
                        time_ago = "Just now"
                        if pub_date is not None and pub_date.text:
                            try:
                                from email.utils import parsedate_to_datetime
                                dt = parsedate_to_datetime(pub_date.text)
                                time_ago = get_time_ago(dt)
                            except:
                                pass
                        
                        # Simple sentiment detection from title
                        title_lower = title.text.lower() if title.text else ""
                        sentiment = "NEUTRAL"
                        if any(w in title_lower for w in ["surge", "soar", "rally", "bullish", "gain", "rise", "record", "inflow", "adoption"]):
                            sentiment = "BULLISH"
                        elif any(w in title_lower for w in ["crash", "drop", "fall", "bearish", "decline", "plunge", "hack", "investigation", "ban"]):
                            sentiment = "BEARISH"
                        
                        # Detect currencies
                        currencies = []
                        if "bitcoin" in title_lower or "btc" in title_lower:
                            currencies.append("BTC")
                        if "ethereum" in title_lower or "eth" in title_lower:
                            currencies.append("ETH")
                        if "solana" in title_lower or "sol" in title_lower:
                            currencies.append("SOL")
                        
                        news_items.append({
                            "title": title.text[:100] if title.text else "",
                            "url": link.text if link is not None else "",
                            "source": "CoinDesk",
                            "sentiment": sentiment,
                            "sentimentColor": "green" if sentiment == "BULLISH" else "red" if sentiment == "BEARISH" else "zinc",
                            "timeAgo": time_ago,
                            "currencies": currencies[:2]
                        })
        except Exception as e:
            logger.warning(f"CoinDesk RSS error: {e}")
        
        # Source 2: CoinTelegraph RSS (free, no auth)
        try:
            res = await client.get("https://cointelegraph.com/rss")
            if res.status_code == 200:
                root = ET.fromstring(res.text)
                for item in root.findall('.//item')[:limit//2]:
                    title = item.find('title')
                    link = item.find('link')
                    pub_date = item.find('pubDate')
                    
                    if title is not None:
                        time_ago = "Just now"
                        if pub_date is not None and pub_date.text:
                            try:
                                from email.utils import parsedate_to_datetime
                                dt = parsedate_to_datetime(pub_date.text)
                                time_ago = get_time_ago(dt)
                            except:
                                pass
                        
                        title_lower = title.text.lower() if title.text else ""
                        sentiment = "NEUTRAL"
                        if any(w in title_lower for w in ["surge", "soar", "rally", "bullish", "gain", "rise", "record", "inflow", "adoption", "pump"]):
                            sentiment = "BULLISH"
                        elif any(w in title_lower for w in ["crash", "drop", "fall", "bearish", "decline", "plunge", "hack", "investigation", "ban", "dump"]):
                            sentiment = "BEARISH"
                        
                        currencies = []
                        if "bitcoin" in title_lower or "btc" in title_lower:
                            currencies.append("BTC")
                        if "ethereum" in title_lower or "eth" in title_lower:
                            currencies.append("ETH")
                        if "solana" in title_lower or "sol" in title_lower:
                            currencies.append("SOL")
                        
                        news_items.append({
                            "title": title.text[:100] if title.text else "",
                            "url": link.text if link is not None else "",
                            "source": "CoinTelegraph",
                            "sentiment": sentiment,
                            "sentimentColor": "green" if sentiment == "BULLISH" else "red" if sentiment == "BEARISH" else "zinc",
                            "timeAgo": time_ago,
                            "currencies": currencies[:2]
                        })
        except Exception as e:
            logger.warning(f"CoinTelegraph RSS error: {e}")
    
    if news_items:
        # Sort by recency (most recent first based on timeAgo)
        return {"success": True, "news": news_items[:limit], "count": len(news_items)}
    
    # Fallback if RSS feeds fail
    logger.warning("All news sources failed, using fallback")
    return {
        "success": True,
        "news": [
            {"title": "Fed signals unchanged rates through Q2", "sentiment": "NEUTRAL", "sentimentColor": "zinc", "timeAgo": "2m", "source": "Reuters", "currencies": ["BTC"]},
            {"title": "BlackRock IBIT sees record $500M inflow", "sentiment": "BULLISH", "sentimentColor": "green", "timeAgo": "8m", "source": "Bloomberg", "currencies": ["BTC"]},
            {"title": "Tether under investigation by DOJ", "sentiment": "BEARISH", "sentimentColor": "red", "timeAgo": "15m", "source": "WSJ", "currencies": ["USDT"]},
            {"title": "ETH staking rewards increase to 4.2%", "sentiment": "BULLISH", "sentimentColor": "green", "timeAgo": "23m", "source": "CoinDesk", "currencies": ["ETH"]},
            {"title": "SEC delays spot ETH ETF decision", "sentiment": "NEUTRAL", "sentimentColor": "zinc", "timeAgo": "45m", "source": "The Block", "currencies": ["ETH"]},
        ],
        "source": "fallback"
    }


def get_time_ago(dt):
    """Convert datetime to human readable time ago."""
    from datetime import datetime, timezone
    now = datetime.now(timezone.utc)
    diff = now - dt
    
    seconds = diff.total_seconds()
    if seconds < 60:
        return "Just now"
    elif seconds < 3600:
        mins = int(seconds / 60)
        return f"{mins}m ago"
    elif seconds < 86400:
        hours = int(seconds / 3600)
        return f"{hours}h ago"
    else:
        days = int(seconds / 86400)
        return f"{days}d ago"


# =============================================================================
# HEALTH CHECK
# =============================================================================

@app.get("/health")
async def health():
    """Health check."""
    return {
        "status": "ok",
        "service": "BASTION Terminal API",
        "version": "1.0.0",
        "helsinki_url": helsinki.base_url if helsinki else "not initialized",
        "websocket_connections": len(active_connections),
        "supported_symbols": len(SUPPORTED_SYMBOLS),
        "timestamp": datetime.now().isoformat()
    }


# =============================================================================
# RUN
# =============================================================================

# Vercel serverless handler - export both app and handler
try:
    from mangum import Mangum
    handler = Mangum(app, lifespan="off")
except ImportError:
    handler = app  # Fallback to FastAPI app directly

# For Vercel - they sometimes expect 'app' at module level
# which we already have

if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.environ.get("PORT", 8888))
    uvicorn.run(app, host="0.0.0.0", port=port)

